{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Defaulting to user installation because normal site-packages is not writeable\n",
      "Obtaining file:///home/jupyter-skenjeye%40broadinst-05974/AutoTrain/gym-autotrain\n",
      "Requirement already satisfied: gym in /home/jupyter-skenjeye@broadinst-05974/.local/lib/python3.7/site-packages (from gym-autotrain==0.0.1) (0.17.2)\n",
      "Requirement already satisfied: numpy>=1.10.4 in /opt/tljh/user/lib/python3.7/site-packages (from gym->gym-autotrain==0.0.1) (1.18.1)\n",
      "Requirement already satisfied: scipy in /opt/tljh/user/lib/python3.7/site-packages (from gym->gym-autotrain==0.0.1) (1.4.1)\n",
      "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /home/jupyter-skenjeye@broadinst-05974/.local/lib/python3.7/site-packages (from gym->gym-autotrain==0.0.1) (1.5.0)\n",
      "Requirement already satisfied: cloudpickle<1.4.0,>=1.2.0 in /opt/tljh/user/lib/python3.7/site-packages (from gym->gym-autotrain==0.0.1) (1.3.0)\n",
      "Requirement already satisfied: future in /opt/tljh/user/lib/python3.7/site-packages (from pyglet<=1.5.0,>=1.4.0->gym->gym-autotrain==0.0.1) (0.18.2)\n",
      "Installing collected packages: gym-autotrain\n",
      "  Attempting uninstall: gym-autotrain\n",
      "    Found existing installation: gym-autotrain 0.0.1\n",
      "    Uninstalling gym-autotrain-0.0.1:\n",
      "      Successfully uninstalled gym-autotrain-0.0.1\n",
      "  Running setup.py develop for gym-autotrain\n",
      "Successfully installed gym-autotrain\n"
     ]
    }
   ],
   "source": [
    "! pip install -e gym-autotrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions.laplace import Laplace\n",
    "import torch.utils.data as torchdata\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import pickle as pkl\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "import gym\n",
    "from gym import error, spaces, utils\n",
    "from gym.utils import seeding\n",
    "\n",
    "import gym_autotrain.envs.utils as utils\n",
    "\n",
    "from gym_autotrain.envs.thresholdout import Thresholdout\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torch.utils.data as  torchdata\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from pathlib import Path\n",
    "from functools import partial\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path('./data')\n",
    "DATA_SPLIT = 0.6\n",
    "\n",
    "ENV_PATH = Path('./autotrain-run')\n",
    "ENV_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "DEVICE = torch.device(\"cuda:3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "CLASSES = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')\n",
    "\n",
    "def splitds(train, test, no_signal=False, pct_cap=None):\n",
    "    X = np.concatenate((train.data,test.data), axis=0)\n",
    "    Y = train.targets + test.targets\n",
    "    \n",
    "    if pct_cap:\n",
    "        cap = int(pct_cap*len(X))\n",
    "        X, Y = X[:cap], Y[:cap]\n",
    "        \n",
    "    \n",
    "    if no_signal:\n",
    "        print('suffling labels')\n",
    "        np.random.shuffle(Y)\n",
    "    \n",
    "    split_id = int(len(X) * DATA_SPLIT)\n",
    "    train.data, train.targets = X[:split_id], Y[:split_id]\n",
    "    test.data, test.targets = X[split_id:], Y[split_id:]\n",
    "\n",
    "def get_dataset(tfms, no_signal=False, pct_cap=None):\n",
    "    train = torchvision.datasets.CIFAR10(root=DATA_ROOT / 'cifar-10-data', train=True,\n",
    "                                        download=True, transform=tfms)\n",
    "\n",
    "    holdout = torchvision.datasets.CIFAR10(root=DATA_ROOT / 'cifar-10-data', train=False,\n",
    "                                           download=True, transform=tfms)\n",
    "    \n",
    "    splitds(train, holdout, no_signal, pct_cap)\n",
    "    \n",
    "    print(f'length of trainset: [{len(train)}]; len of holdout: [{len(holdout)}]')\n",
    "    \n",
    "    return train, holdout\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "length of trainset: [3600]; len of holdout: [2400]\n"
     ]
    }
   ],
   "source": [
    "normalize = T.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                        std=[0.229, 0.224, 0.225])\n",
    "\n",
    "TFMS = T.Compose([T.Resize(256), T.CenterCrop(224), T.ToTensor(), normalize])\n",
    "\n",
    "train, holdout = get_dataset(TFMS, pct_cap=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(data: torchdata.DataLoader, model: nn.Module): # phi\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data,total=len(data)):\n",
    "            images, labels = batch[0].to(DEVICE), batch[1]\n",
    "            outputs = model(images).cpu()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "  (relu): ReLU(inplace=True)\n",
       "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  (layer1): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): BasicBlock(\n",
       "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (downsample): Sequential(\n",
       "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (1): BasicBlock(\n",
       "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU(inplace=True)\n",
       "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "  (fc): Linear(in_features=512, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "backbone = models.resnet18(pretrained=False)\n",
    "backbone.fc = nn.Linear(512, len(CLASSES))\n",
    "backbone.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_o(loss_vec:np.array, lr:float, phi_val:float):\n",
    "      return np.concatenate((loss_vec, [lr, phi_val]), axis=0)\n",
    "\n",
    "\n",
    "class AutoTrainEnvironment(gym.Env):\n",
    "      metadata = {'render.modes': ['human']}\n",
    "\n",
    "      def __init__(self):\n",
    "            pass\n",
    "\n",
    "      def __repr__(self):\n",
    "            return f\"\"\"AutoTrainEnvironment with the following parameters:\n",
    "                        lr_init={self.lr_init}, inter_reward={self._inter_reward}, H={self.H}, K={self.K}, T={self.T}\"\"\"\n",
    "      \n",
    "      def log(self, s):\n",
    "            if self.v: print(f'[time_step:{self.time_step}] ',s)\n",
    "\n",
    "      def init(self, backbone: nn.Module,  phi: callable, savedir:Path,\n",
    "             trnds:torchdata.Dataset, valds:torchdata.Dataset, \n",
    "             T=3, H=5, S=2, lr_init=3e-4, inter_reward=0.05,\n",
    "             num_workers=4, bs=16, v=False, device=None):\n",
    "            \"\"\"\n",
    "            params:\n",
    "                  - backbone: nn.Module, neural network architecture for training\n",
    "                  - trainds, valds: Dataset, train and validation datasets\n",
    "                  - phi: callable, function to be optimised  \n",
    "\n",
    "                  - T: num batch updates that constitutes one time step for the environment\n",
    "                  - H: length of rewind vector\n",
    "                  - S: sampling interval, determines K which is the loss vector\n",
    "            \"\"\"\n",
    "            # experiment paramter setup\n",
    "            \n",
    "            self.T, self.H, self.sampling_interval = T, H, S\n",
    "            self.K = self.T // self.sampling_interval\n",
    "            \n",
    "            self._inter_reward = inter_reward\n",
    "            self.v = v # is verbose\n",
    "            self.device = device\n",
    "            self.savedir = savedir\n",
    "            # rewind actions * lr_scale actions [decrease  10%, keep, increase 10%] + reinit + stop \n",
    "            self.action_space_dim = self.H*3 + 2 \n",
    "            # loss_vec of size K + lr + phi_val\n",
    "            self.observation_space_dim = self.K + 2\n",
    "            \n",
    "            self.time_step = 0\n",
    "\n",
    "            # model \n",
    "            self.ll = StateLinkedList(savedir=savedir, dim=self.observation_space_dim)\n",
    "            self.backbone = backbone\n",
    "\n",
    "            self.criterion = nn.CrossEntropyLoss()\n",
    "            self.lr_init = self._curr_lr = lr_init\n",
    "\n",
    "            self._init_backbone()\n",
    "\n",
    "            # package data\n",
    "            self.trnds, self.valds = trnds, valds\n",
    "\n",
    "            self.trndl, self.fixdl, self.valdl =  utils.create_dls(self.trnds, self.valds, bs=bs, num_workers=num_workers)\n",
    "\n",
    "\n",
    "            # Thresholdout & statistic of interest\n",
    "            self.thresholdout = Thresholdout(self.trndl, self.valdl)\n",
    "            self.phi = phi \n",
    "            self._phi_func = partial(self.phi, model=self.backbone) #  does partial work on this\n",
    "\n",
    "            self._init_phi()\n",
    "\n",
    "            # calculate the sampling interval\n",
    "\n",
    "            self.logdf = pd.DataFrame(columns=['t', 'reward', 'is_stop', 'action_id'])\n",
    "\n",
    "            self._add_observation(np.zeros(K), self._get_phi_val())\n",
    "\n",
    "            self.log(f'environment initialised : {self.__repr__()}')\n",
    "            \n",
    "            return self.ll.get_observations(self.H)\n",
    "\n",
    "      def  _init_phi(self):\n",
    "            self.log('initialised phi value: started ...')\n",
    "            self._prev_phi_val = 0\n",
    "            self._cur_phi_val = self.thresholdout.verify(self._phi_func)\n",
    "            self._last_phi_update = self.time_step\n",
    "            self.log('initialised phi value: done')\n",
    "\n",
    "      def _init_backbone(self):\n",
    "\n",
    "            if self.device:\n",
    "                  self.backbone.to(self.device) # check\n",
    "\n",
    "            utils.init_params(self.backbone)\n",
    "\n",
    "            self.opt = optim.Adam(self.backbone.parameters(), lr=self.lr_init)\n",
    "            self.log(f'initialised backbone parameters & optimizer')\n",
    "\n",
    "\n",
    "      def _get_phi_val(self) -> float:\n",
    "            if self._last_phi_update != self.time_step:\n",
    "                  self._prev_phi_val = self._cur_phi_val\n",
    "                  self._cur_phi_val = self.thresholdout.verify(self._phi_func)\n",
    "                  self._last_phi_update = self.time_step\n",
    "\n",
    "            return self._cur_phi_val\n",
    "\n",
    "      def _add_observation(self,  loss_vec: np.array,  phi_val: float):\n",
    "            o_state = ObservationAndState(\n",
    "                  param_dict=self.backbone.state_dict(),\n",
    "                  o=make_o(loss_vec, self._curr_lr, phi_val)\n",
    "            )\n",
    "            self.ll.append(o_state)\n",
    "            self.log(f'added observation')\n",
    "\n",
    "      def visualise_data(self):\n",
    "            \"\"\"\n",
    "            two plots: \n",
    "                  - class distribution of training data\n",
    "                  - class distribution of validation data\n",
    "            \"\"\"\n",
    "            pass \n",
    "\n",
    "      def step(self, action: int): \n",
    "            \"\"\"\n",
    "            step(self, action: int):\n",
    "                @action: index of the max value of the action probability vector \n",
    "            \n",
    "            \"\"\"\n",
    "\n",
    "            self.log(f'action [{action}] recieved')\n",
    "\n",
    "            is_stop = action == self.action_space_dim\n",
    "            is_reinit = action == self.action_space_dim - 1\n",
    "\n",
    "            if is_stop:\n",
    "                  final_reward = self._compute_final_reward()\n",
    "                  self.log(f'recieved STOP signal, final reward is: [{final_reward}]')\n",
    "                  return None, final_reward, True, {}\n",
    "\n",
    "\n",
    "            # lr and rewind steps\n",
    "            if action < 5:\n",
    "                  self._scale_lr(0.9)\n",
    "                  rewind_steps = action\n",
    "                  self.log(f'decreased lr by 10% -> [lr:{self._curr_lr}]')\n",
    "            elif action >= 5 and action < 10:\n",
    "                  rewind_steps = action - 5 \n",
    "            else:\n",
    "                  self._scale_lr(1.1)\n",
    "                  self.log(f'increased lr by 10% -> [lr:{self._curr_lr}]')\n",
    "                  rewind_steps = action - 10\n",
    "            \n",
    "\n",
    "            if rewind_steps >= self.ll.len or is_reinit:\n",
    "                  self.log(f'recieved RE-INIT signal or rewind_steps[{rewind_steps}] > len(ll)')\n",
    "\n",
    "                  self._init_backbone()\n",
    "\n",
    "                  self._init_phi()\n",
    "                  self._add_observation(np.zeros(self.K), self._get_phi_val()) # do we add here or no\n",
    "\n",
    "                  self.ll = StateLinkedList(savedir=self.savedir, dim=self.observation_space_dim)\n",
    "\n",
    "            elif rewind_steps != 0:\n",
    "                  self.log(f'rewind weights [{rewind_steps}] steps back')\n",
    "                  self.ll.rewind(rewind_steps)\n",
    "                  o = self.ll[self.ll.len-1]  # get the latest state after rewind\n",
    "                  self.backbone.load_state_dict(o['param_dict'])\n",
    "\n",
    "            # do training \n",
    "            loss_vec = self._train_one_cycle()\n",
    "            # set current observation\n",
    "            self._add_observation(loss_vec, self._get_phi_val()) # whats this for then\n",
    "\n",
    "            # get last H observations\n",
    "            o_history = self.ll.get_observations(self.H)\n",
    "\n",
    "            # compute intermediate reward\n",
    "            step_reward = self._compute_intermediate_reward()\n",
    "            self.log(f'reward at the end of time step is [{step_reward}]')\n",
    "\n",
    "            return o_history, step_reward, False, {}\n",
    "\n",
    "\n",
    "      def _scale_lr(self, scale_factor):\n",
    "\n",
    "            for g in self.opt.param_groups:\n",
    "                  g['lr'] *= scale_factor\n",
    "\n",
    "            self._curr_lr *= scale_factor\n",
    "\n",
    "\n",
    "      def _train_one_cycle(self, loss_vec=None, steps=0):\n",
    "            print('train called, loss_vec: ', loss_vec, ' steps ',steps)\n",
    "            if loss_vec is None:\n",
    "                  loss_vec = np.zeros(self.K)\n",
    "\n",
    "            self.backbone.train()\n",
    "            for i, batch in enumerate(self.trndl):\n",
    "                  inputs, labels = batch[0], batch[1]\n",
    "\n",
    "                  if self.device:\n",
    "                      inputs, labels = inputs.to(self.device), labels.to(self.device)\n",
    "            \n",
    "                  self.opt.zero_grad()\n",
    "\n",
    "                  outputs = self.backbone(inputs)\n",
    "                  loss = self.criterion(outputs, labels)\n",
    "                  loss.backward()\n",
    "                  self.opt.step()\n",
    "\n",
    "                  steps += 1\n",
    "                    \n",
    "                  if steps >= self.T:\n",
    "                        self.time_step += 1 # this defines the time step\n",
    "                        return loss_vec\n",
    "                  \n",
    "                  if steps % self.sampling_interval == 0:\n",
    "                        loss_vec[(steps // self.sampling_interval) - 1] = loss.item()\n",
    "                \n",
    "            return self._train_one_cycle(loss_vec=loss_vec, steps=steps)\n",
    "\n",
    "      def _compute_final_reward(self):\n",
    "            return self._get_phi_val()\n",
    "\n",
    "      def _compute_intermediate_reward(self):\n",
    "            delta = self._get_phi_val() - self._prev_phi_val\n",
    "            if  delta > 0:\n",
    "                  return self._inter_reward\n",
    "            else:\n",
    "                  return -self._inter_reward\n",
    "\n",
    "\n",
    "      def reset(self):\n",
    "\n",
    "            return self.init(self.backbone, self.phi, self.savedir, self.trnds, self.valds,\n",
    "            T=self.T, H=self.H, K=self.K, lr_init=self.lr_init, inter_reward=self._inter_reward,\n",
    "            num_workers=self.num_workers, bs=self.bs, v=self.v, device=self.device)\n",
    "\n",
    "      def render(self, mode='human', close=False):\n",
    "            \"\"\"render observation; for that need to add logs\"\"\"\n",
    "            pass\n",
    "\n",
    "\n",
    "\n",
    "class ObservationAndState:\n",
    "      def __init__(self, param_dict: dict, o: np.array):\n",
    "            self.param_dict = param_dict\n",
    "            self.o = o\n",
    "\n",
    "            self.dim = self.o.size\n",
    "\n",
    "      def to_dict(self):\n",
    "            return {\n",
    "                  'param_dict': self.param_dict,\n",
    "                  'o': self.o\n",
    "            }\n",
    "\n",
    "      def __repr__(self):\n",
    "            return f\"ObservationAndState Object --> o={self.o} param_dict={self.param_dict}\"\n",
    "\n",
    "      \n",
    "            \n",
    "\n",
    "class StateLinkedList:\n",
    "\n",
    "      def __init__(self, savedir: Path, dim: int):\n",
    "\n",
    "            if type(savedir) == str:\n",
    "                  savedir = Path(savedir) \n",
    "\n",
    "            assert savedir.exists() and savedir.is_dir(), \"please make sure save path exists and is directory\"\n",
    "            assert dim > 0\n",
    "\n",
    "            self.savedir = savedir\n",
    "            self.dim = dim # observation dimension \n",
    "\n",
    "            self.len = 0 # the id of the next node\n",
    "\n",
    "      def get_observations(self, size):\n",
    "            os = []\n",
    "            if size > self.len:\n",
    "                  for _ in range(size - self.len):\n",
    "                        os.append(np.zeros(self.dim))\n",
    "                  size = self.len\n",
    "\n",
    "            os += [self[i].o for i in range(size)]\n",
    "            return np.vstack(os)\n",
    "            \n",
    "\n",
    "      def append(self, state: ObservationAndState):\n",
    "\n",
    "            new_node_path = self.node_path(self.len)\n",
    "            torch.save(state, new_node_path)\n",
    "            self.len += 1\n",
    "\n",
    "      def node_path(self, idx) -> Path:\n",
    "            return self.savedir / f'state_{idx}.ckpt'\n",
    "\n",
    "\n",
    "      def __len__(self):\n",
    "            return self.len\n",
    "\n",
    "      def __getitem__(self, idx):\n",
    "\n",
    "            if idx >= self.len:\n",
    "                  raise ValueError('idx too large')\n",
    "\n",
    "            return torch.load(self.node_path(idx))\n",
    "            \n",
    "\n",
    "      def rewind(self, steps: int):\n",
    "\n",
    "            steps = min(steps, self.len)\n",
    "            \n",
    "            for i in range(1, steps+1):\n",
    "                  print('rewind')\n",
    "                  nodepath = self.node_path(self.len - i)\n",
    "                  nodepath.unlink()\n",
    "\n",
    "            self.len -= steps\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "337"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "H = 5\n",
    "BS = 16\n",
    "S = 2 # sampling interval\n",
    "T = len(train) // BS * 3 # three epochs\n",
    "K = T // S\n",
    "K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[time_step:0]  initialised backbone parameters & optimizer\n",
      "[time_step:0]  initialised phi value: started ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "395e756bebba4aae95fc5b5a54c925f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=225.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "baf0e9d527044f13b501c1426c6f0af9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=150.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[time_step:0]  initialised phi value: done\n",
      "[time_step:0]  added observation\n",
      "[time_step:0]  environment initialised : AutoTrainEnvironment with the following parameters:\n",
      "                        lr_init=0.0003, inter_reward=0.05, H=5, K=337, T=675\n"
     ]
    }
   ],
   "source": [
    "env = AutoTrainEnvironment()\n",
    "\n",
    "\n",
    "\n",
    "ob = env.init(backbone=backbone,  phi=accuracy, savedir=ENV_PATH,\n",
    "         trnds=train, valds=holdout, \n",
    "         T=T, H=H, S=2, lr_init=3e-4, inter_reward=0.05,\n",
    "         num_workers=4, bs=BS, v=True, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def agent():\n",
    "    return np.random.choice(range(env.action_space_dim))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[time_step:0]  action [0] recieved\n",
      "[time_step:0]  decreased lr by 10% -> [lr:0.00027]\n",
      "train called, loss_vec:  None  steps  0\n",
      "train called, loss_vec:  [2.6716814  1.89849043 1.46394598 1.46715999 1.51975882 1.01550984\n",
      " 1.1220268  0.67024863 0.5065791  0.5564186  0.40669262 0.51554328\n",
      " 0.35622099 0.44355494 0.48641109 0.35580549 0.43212035 0.26500952\n",
      " 0.27012148 0.35450253 0.14052968 0.18816264 0.42199397 0.09489837\n",
      " 0.19831866 0.21077883 0.11365804 0.07457419 0.11297897 0.07429682\n",
      " 0.24430957 0.06534055 0.24004477 0.08660294 0.41303706 0.07469225\n",
      " 0.09402582 0.22449659 0.12264282 0.06622043 0.13399404 0.06270418\n",
      " 0.05542123 0.2226918  0.21362366 0.21102114 0.1198792  0.1962316\n",
      " 0.11414631 0.25017709 0.24400733 0.09989141 0.12945461 0.12918201\n",
      " 0.21318395 0.23703092 0.4249813  0.33737153 0.23304154 0.22955856\n",
      " 0.16239452 0.23685353 0.35459965 0.08655542 0.25610399 0.28174251\n",
      " 0.15637863 0.13442664 0.20358257 0.26980224 0.06227034 0.29633158\n",
      " 0.30740952 0.10634193 0.25232834 0.10382569 0.07704481 0.2559174\n",
      " 0.61242193 0.2016139  0.26684785 0.33359915 0.26172924 0.13693061\n",
      " 0.35444772 0.20887946 0.20910668 0.02807483 0.16731872 0.41783369\n",
      " 0.13141134 0.07834232 0.09286678 0.08276686 0.34252608 0.03522167\n",
      " 0.07345518 0.25417814 0.31867081 0.20300156 0.18343864 0.12060937\n",
      " 0.27035496 0.04972973 0.19273788 0.18448287 0.05402806 0.11814551\n",
      " 0.19133055 0.26598498 0.09560497 0.4053821  0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]  steps  225\n",
      "train called, loss_vec:  [2.6716814  1.89849043 1.46394598 1.46715999 1.51975882 1.01550984\n",
      " 1.1220268  0.67024863 0.5065791  0.5564186  0.40669262 0.51554328\n",
      " 0.35622099 0.44355494 0.48641109 0.35580549 0.43212035 0.26500952\n",
      " 0.27012148 0.35450253 0.14052968 0.18816264 0.42199397 0.09489837\n",
      " 0.19831866 0.21077883 0.11365804 0.07457419 0.11297897 0.07429682\n",
      " 0.24430957 0.06534055 0.24004477 0.08660294 0.41303706 0.07469225\n",
      " 0.09402582 0.22449659 0.12264282 0.06622043 0.13399404 0.06270418\n",
      " 0.05542123 0.2226918  0.21362366 0.21102114 0.1198792  0.1962316\n",
      " 0.11414631 0.25017709 0.24400733 0.09989141 0.12945461 0.12918201\n",
      " 0.21318395 0.23703092 0.4249813  0.33737153 0.23304154 0.22955856\n",
      " 0.16239452 0.23685353 0.35459965 0.08655542 0.25610399 0.28174251\n",
      " 0.15637863 0.13442664 0.20358257 0.26980224 0.06227034 0.29633158\n",
      " 0.30740952 0.10634193 0.25232834 0.10382569 0.07704481 0.2559174\n",
      " 0.61242193 0.2016139  0.26684785 0.33359915 0.26172924 0.13693061\n",
      " 0.35444772 0.20887946 0.20910668 0.02807483 0.16731872 0.41783369\n",
      " 0.13141134 0.07834232 0.09286678 0.08276686 0.34252608 0.03522167\n",
      " 0.07345518 0.25417814 0.31867081 0.20300156 0.18343864 0.12060937\n",
      " 0.27035496 0.04972973 0.19273788 0.18448287 0.05402806 0.11814551\n",
      " 0.19133055 0.26598498 0.09560497 0.4053821  0.15068713 0.29867712\n",
      " 0.03095818 0.24921083 0.0695222  0.10233253 0.15650617 0.12438548\n",
      " 0.08080816 0.21561837 0.02498174 0.05948424 0.15268755 0.08181173\n",
      " 0.12290823 0.07661781 0.10850462 0.18811268 0.03189865 0.06635004\n",
      " 0.20040053 0.03745991 0.1259214  0.20669152 0.04742619 0.19553839\n",
      " 0.07978147 0.05636424 0.10082598 0.05030349 0.28399509 0.52645856\n",
      " 0.1430307  0.02543923 0.25296727 0.05995837 0.04143    0.01071367\n",
      " 0.18083757 0.27320823 0.1356301  0.04748401 0.04074758 0.02379698\n",
      " 0.02711201 0.03336915 0.02641639 0.19642247 0.24382053 0.0380612\n",
      " 0.0126335  0.17000324 0.29993773 0.4034715  0.05367503 0.12587187\n",
      " 0.36908168 0.08737883 0.02894059 0.17957844 0.15247534 0.01293328\n",
      " 0.01586357 0.02559873 0.02901757 0.03944713 0.19309251 0.11200514\n",
      " 0.03101975 0.02989179 0.10199736 0.05821782 0.04816517 0.02745122\n",
      " 0.08642346 0.09254608 0.06564397 0.24317561 0.04236102 0.00650531\n",
      " 0.23309717 0.01985744 0.09226552 0.0125111  0.11040393 0.05996194\n",
      " 0.11255369 0.20858084 0.22880428 0.04537556 0.17132352 0.06405701\n",
      " 0.16731182 0.18139076 0.0722779  0.0617319  0.04056427 0.0213379\n",
      " 0.12903208 0.11614606 0.08909366 0.08584899 0.10777247 0.18010984\n",
      " 0.01049805 0.30978012 0.07100695 0.04120404 0.22252731 0.09274969\n",
      " 0.02535865 0.16479571 0.02822071 0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.         0.         0.         0.         0.         0.\n",
      " 0.        ]  steps  450\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4de8cacec4cd48658be31278bc11cb23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=225.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2379a6f131fc4e20864429a67b38097b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=150.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[2.6716814  1.89849043 1.46394598 1.46715999 1.51975882 1.01550984\n",
      " 1.1220268  0.67024863 0.5065791  0.5564186  0.40669262 0.51554328\n",
      " 0.35622099 0.44355494 0.48641109 0.35580549 0.43212035 0.26500952\n",
      " 0.27012148 0.35450253 0.14052968 0.18816264 0.42199397 0.09489837\n",
      " 0.19831866 0.21077883 0.11365804 0.07457419 0.11297897 0.07429682\n",
      " 0.24430957 0.06534055 0.24004477 0.08660294 0.41303706 0.07469225\n",
      " 0.09402582 0.22449659 0.12264282 0.06622043 0.13399404 0.06270418\n",
      " 0.05542123 0.2226918  0.21362366 0.21102114 0.1198792  0.1962316\n",
      " 0.11414631 0.25017709 0.24400733 0.09989141 0.12945461 0.12918201\n",
      " 0.21318395 0.23703092 0.4249813  0.33737153 0.23304154 0.22955856\n",
      " 0.16239452 0.23685353 0.35459965 0.08655542 0.25610399 0.28174251\n",
      " 0.15637863 0.13442664 0.20358257 0.26980224 0.06227034 0.29633158\n",
      " 0.30740952 0.10634193 0.25232834 0.10382569 0.07704481 0.2559174\n",
      " 0.61242193 0.2016139  0.26684785 0.33359915 0.26172924 0.13693061\n",
      " 0.35444772 0.20887946 0.20910668 0.02807483 0.16731872 0.41783369\n",
      " 0.13141134 0.07834232 0.09286678 0.08276686 0.34252608 0.03522167\n",
      " 0.07345518 0.25417814 0.31867081 0.20300156 0.18343864 0.12060937\n",
      " 0.27035496 0.04972973 0.19273788 0.18448287 0.05402806 0.11814551\n",
      " 0.19133055 0.26598498 0.09560497 0.4053821  0.15068713 0.29867712\n",
      " 0.03095818 0.24921083 0.0695222  0.10233253 0.15650617 0.12438548\n",
      " 0.08080816 0.21561837 0.02498174 0.05948424 0.15268755 0.08181173\n",
      " 0.12290823 0.07661781 0.10850462 0.18811268 0.03189865 0.06635004\n",
      " 0.20040053 0.03745991 0.1259214  0.20669152 0.04742619 0.19553839\n",
      " 0.07978147 0.05636424 0.10082598 0.05030349 0.28399509 0.52645856\n",
      " 0.1430307  0.02543923 0.25296727 0.05995837 0.04143    0.01071367\n",
      " 0.18083757 0.27320823 0.1356301  0.04748401 0.04074758 0.02379698\n",
      " 0.02711201 0.03336915 0.02641639 0.19642247 0.24382053 0.0380612\n",
      " 0.0126335  0.17000324 0.29993773 0.4034715  0.05367503 0.12587187\n",
      " 0.36908168 0.08737883 0.02894059 0.17957844 0.15247534 0.01293328\n",
      " 0.01586357 0.02559873 0.02901757 0.03944713 0.19309251 0.11200514\n",
      " 0.03101975 0.02989179 0.10199736 0.05821782 0.04816517 0.02745122\n",
      " 0.08642346 0.09254608 0.06564397 0.24317561 0.04236102 0.00650531\n",
      " 0.23309717 0.01985744 0.09226552 0.0125111  0.11040393 0.05996194\n",
      " 0.11255369 0.20858084 0.22880428 0.04537556 0.17132352 0.06405701\n",
      " 0.16731182 0.18139076 0.0722779  0.0617319  0.04056427 0.0213379\n",
      " 0.12903208 0.11614606 0.08909366 0.08584899 0.10777247 0.18010984\n",
      " 0.01049805 0.30978012 0.07100695 0.04120404 0.22252731 0.09274969\n",
      " 0.02535865 0.16479571 0.02822071 0.08103979 0.09391579 0.03057799\n",
      " 0.03881803 0.12784767 0.13349724 0.30232567 0.17961122 0.03478664\n",
      " 0.06072411 0.01216736 0.0395368  0.0886434  0.22706638 0.1464034\n",
      " 0.05370867 0.05839004 0.14688793 0.11576079 0.04884821 0.06567571\n",
      " 0.03891042 0.15137075 0.05925563 0.03343624 0.17650475 0.11090681\n",
      " 0.38488498 0.02187717 0.03241533 0.05783975 0.02003577 0.28782511\n",
      " 0.16661258 0.15686604 0.01745036 0.03398681 0.08892453 0.16222742\n",
      " 0.18821543 0.06108618 0.02775931 0.49596888 0.05230501 0.02958512\n",
      " 0.08133736 0.0528706  0.32443345 0.0657793  0.03293633 0.05765781\n",
      " 0.12480681 0.10296482 0.0513899  0.06312123 0.40957862 0.22461644\n",
      " 0.03597665 0.2039717  0.12761503 0.19943938 0.09232941 0.04581514\n",
      " 0.02243072 0.21597968 0.04712903 0.04269582 0.65856212 0.85454589\n",
      " 0.03754884 0.08495858 0.01776922 0.02861667 0.01665387 0.08212095\n",
      " 0.24818522 0.20880541 0.1247274  0.25486445 0.08160385 0.026218\n",
      " 0.11655079 0.10003437 0.12437913 0.02913874 0.18865174 0.04490191\n",
      " 0.06228843 0.2695896  0.08323747 0.15339369 0.26531619 0.02330053\n",
      " 0.02468958 0.65735924 0.07187778 0.0166887  0.03987774 0.68101323\n",
      " 0.12683991 0.11150032 0.07780209 0.11861727 0.32357398 0.08045685\n",
      " 0.07504988 0.28897938 0.10537058 0.03549275 0.36077625 0.09854978\n",
      " 0.4309729 ] 0.5366898748605058 0.00027\n",
      "[time_step:1]  added observation\n",
      "[time_step:1]  reward at the end of time step is [0.05]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([[0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 0.00000000e+00, 0.00000000e+00],\n",
       "        [0.00000000e+00, 0.00000000e+00, 0.00000000e+00, ...,\n",
       "         0.00000000e+00, 3.00000000e-04, 8.47065400e-02],\n",
       "        [2.67168140e+00, 1.89849043e+00, 1.46394598e+00, ...,\n",
       "         4.30972904e-01, 2.70000000e-04, 5.36689875e-01]]),\n",
       " 0.05,\n",
       " False,\n",
       " {})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.step(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
