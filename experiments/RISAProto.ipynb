{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys, time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append('..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import gym\n",
    "\n",
    "import autotrain\n",
    "import autotrain.gym_env \n",
    "import autotrain.agent.replay_memory as replay_memory\n",
    "\n",
    "# if gpu is to be used\n",
    "DEVICE = torch.device(\"cuda:3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# agent import\n",
    "import random\n",
    "import math\n",
    "from itertools import count\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "import autotrain.agent.dqn as dqn\n",
    "import autotrain.agent.replay_memory as replay_memory\n",
    "\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent Definitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DQN_MLP(nn.Module):\n",
    "    def __init__(self, inputs, outputs):\n",
    "        super().__init__()\n",
    "        self.net = nn.Sequential(\n",
    "            nn.Linear(inputs, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, outputs),\n",
    "            nn.Softmax(),\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.net(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 16\n",
    "GAMMA = 0.999\n",
    "\n",
    "EPS_START = 0.9\n",
    "EPS_END = 0.05\n",
    "EPS_DECAY = 200\n",
    "\n",
    "TARGET_UPDATE = 20 \n",
    "\n",
    "\n",
    "\n",
    "class AutoTrainAgent: \n",
    "\n",
    "    def __init__(self, env, device):\n",
    "        \n",
    "        self.env = env\n",
    "        self.device = device\n",
    "\n",
    "        self.observation_dim = env.observation_space_dim\n",
    "        \n",
    "        # Get number of actions from gym action space\n",
    "        self.n_actions = env.action_space_dim\n",
    "\n",
    "        self.policy_net = dqn.DQN_MLP(self.observation_dim, self.n_actions).to(device)\n",
    "        self.target_net = dqn.DQN_MLP(self.observation_dim, self.n_actions).to(device)\n",
    "        self.target_net.load_state_dict(self.policy_net.state_dict())\n",
    "        self.target_net.eval()\n",
    "\n",
    "        self.optimizer = optim.RMSprop(self.policy_net.parameters())\n",
    "        self.memory = replay_memory.ReplayMemory(10_000)\n",
    "\n",
    "        self.steps_done = 0\n",
    "\n",
    "\n",
    "    def select_action(self, state):\n",
    "        sample = random.random()\n",
    "        eps_threshold = EPS_END + (EPS_START - EPS_END) * \\\n",
    "            math.exp(-1. * self.steps_done / EPS_DECAY)\n",
    "        if sample > eps_threshold:\n",
    "            with torch.no_grad():\n",
    "                # t.max(1) will return largest column value of each row.\n",
    "                # second column on max result is index of where max element was\n",
    "                # found, so we pick action with the larger expected reward.\n",
    "                \n",
    "                if len(state.shape) == 1:\n",
    "                    state = state.view(1, -1)\n",
    "                print(f'[ATA] state dimensions: ', state.shape)\n",
    "                actions = self.policy_net(state)\n",
    "                \n",
    "                return actions.max(-1)[1].view(-1, 1)\n",
    "        else:\n",
    "            print('[ATA] exploration policy enacted')\n",
    "            return torch.tensor([[random.randrange(self.n_actions)]], device=self.device, dtype=torch.long)\n",
    "        \n",
    "        \n",
    "    def optimize_model(self):\n",
    "        if len(self.memory) < BATCH_SIZE:\n",
    "            return\n",
    "        transitions = self.memory.sample(BATCH_SIZE)\n",
    "        # Transpose the batch (see https://stackoverflow.com/a/19343/3343043 for\n",
    "        # detailed explanation). This converts batch-array of Transitions\n",
    "        # to Transition of batch-arrays.\n",
    "        batch = replay_memory.Transition(*zip(*transitions))\n",
    "\n",
    "        # Compute a mask of non-final states and concatenate the batch elements\n",
    "        # (a final state would've been the one after which simulation ended)\n",
    "        non_final_mask = torch.tensor(tuple(map(lambda s: s is not None,\n",
    "                                              batch.next_state)), device=self.device, dtype=torch.bool)\n",
    "        non_final_next_states = torch.stack([s for s in batch.next_state\n",
    "                                                    if s is not None])\n",
    "\n",
    "        state_batch = torch.stack(batch.state)\n",
    "        action_batch = torch.cat(batch.action).view(BATCH_SIZE, 1)\n",
    "        reward_batch = torch.cat(batch.reward)\n",
    "        print(f'[ATA] batch shapes: [{state_batch.shape} {action_batch.shape} {reward_batch.shape}]')\n",
    "\n",
    "        # Compute Q(s_t, a) - the model computes Q(s_t), then we select the\n",
    "        # columns of actions taken. These are the actions which would've been taken\n",
    "        # for each batch state according to policy_net\n",
    "        state_action_values = self.policy_net(state_batch).gather(1, action_batch)\n",
    "\n",
    "        # Compute V(s_{t+1}) for all next states.\n",
    "        # Expected values of actions for non_final_next_states are computed based\n",
    "        # on the \"older\" target_net; selecting their best reward with max(1)[0].\n",
    "        # This is merged based on the mask, such that we'll have either the expected\n",
    "        # state value or 0 in case the state was final.\n",
    "        next_state_values = torch.zeros(BATCH_SIZE, device=self.device)\n",
    "        next_state_values[non_final_mask] = self.target_net(non_final_next_states).max(1)[0].detach()\n",
    "        # Compute the expected Q values\n",
    "        expected_state_action_values = (next_state_values * GAMMA) + reward_batch\n",
    "\n",
    "        # Compute Huber loss\n",
    "        loss = F.smooth_l1_loss(state_action_values, expected_state_action_values.unsqueeze(1))\n",
    "\n",
    "        # Optimize the model\n",
    "        self.optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        for param in self.policy_net.parameters():\n",
    "            param.grad.data.clamp_(-1, 1)\n",
    "        self.optimizer.step()\n",
    "        print('[ATA] DQN optimisation step complete ')\n",
    "        \n",
    "    def _preproc_state(self, state):\n",
    "        return torch.FloatTensor(np.concatenate(state, axis=0)).to(self.device)\n",
    "        \n",
    "    def episode(self, i_episode):\n",
    "        # Initialize the environment and state\n",
    "        global RL_PROGRESS_PATH\n",
    "\n",
    "        state = self._preproc_state(self.env.reset())\n",
    "\n",
    "        for t in count():\n",
    "            start_time = time.time()\n",
    "            \n",
    "            # Select and perform an action\n",
    "            action = self.select_action(state)\n",
    "            next_state, reward, done, _ = self.env.step(action.item())\n",
    "            next_state = self._preproc_state(next_state) if not done else next_state  # for MLP, only one dim\n",
    "            \n",
    "            reward = torch.FloatTensor([reward]).to(self.device)\n",
    "\n",
    "            # Store the transition in memory\n",
    "            self.memory.push(state, action, next_state, reward)\n",
    "\n",
    "            # Move to the next state\n",
    "            state = next_state\n",
    "\n",
    "            # Perform one step of the optimization (on the target network)\n",
    "            self.optimize_model()\n",
    "            print(f'[ATA episode {i_episode}]: took [{time.time() - start_time:.1f}] seconds for one full step')\n",
    "            if done:\n",
    "                break\n",
    "                \n",
    "        self.steps_done += 1\n",
    "\n",
    "        # Update the target network, copying all weights and biases in DQN\n",
    "        if i_episode % TARGET_UPDATE == 0:\n",
    "            self.target_net.load_state_dict(self.policy_net.state_dict())\n",
    "            \n",
    "        print(f'[ATA] replay buffer length: [{len(self.memory)}]')\n",
    "        savepath = RL_PROGRESS_PATH / f'{i_episode}_episode'\n",
    "        savepath.mkdir()\n",
    "        \n",
    "        env.save_env(savepath)\n",
    "        torch.save(self.policy_net.state_dict(), savepath / 'policy_net.ckpt')\n",
    "        torch.save(self.target_net.state_dict(), savepath / 'target_net.ckpt')\n",
    "        self.memory.save(savepath / 'replay_buffer.pkl')\n",
    "\n",
    "        return t\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Environment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Data Prep - MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !rm -rf ./results/full_min_proto_0/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_ROOT = Path('../data')\n",
    "DATA_SPLIT = 0.6\n",
    "\n",
    "ENV_PATH = Path('./results/autotrain-run-risa')\n",
    "ENV_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "RL_PROGRESS_PATH = Path('./results/') \n",
    "RL_PROGRESS_PATH.mkdir(exist_ok=True)\n",
    "RL_PROGRESS_PATH /= 'RISA_proto_1_phi_changes'\n",
    "RL_PROGRESS_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "if any(RL_PROGRESS_PATH.iterdir()):\n",
    "    print('[WARNING!!]: save dir is not empty; agent will not save if folder exists')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = range(10)\n",
    "\n",
    "def reduceds(ds, pct_cap, no_signal=False):\n",
    "    X, Y = ds.data, ds.targets\n",
    "    \n",
    "    if pct_cap:\n",
    "        cap = int(pct_cap*len(X))\n",
    "        X, Y = X[:cap], Y[:cap]\n",
    "        \n",
    "    \n",
    "    if no_signal:\n",
    "        print('suffling labels')\n",
    "        np.random.shuffle(Y)\n",
    "    \n",
    "    ds.data, ds.targets = X, Y\n",
    "\n",
    "def get_dataset(tfms, no_signal=False, pct_cap=None):\n",
    "    train = torchvision.datasets.MNIST(root=DATA_ROOT / 'mnist-data', train=True,\n",
    "                                        download=True, transform=tfms)\n",
    "\n",
    "    holdout = torchvision.datasets.MNIST(root=DATA_ROOT / 'mnist-data', train=False,\n",
    "                                           download=True, transform=tfms)\n",
    "        \n",
    "    # train.data, train.targets = train.data.numpy(),train.targets.numpy()\n",
    "    # holdout.data, holdout.targets = holdout.data.numpy(),  holdout.targets.numpy()\n",
    "    \n",
    "    reduceds(train, pct_cap, no_signal)\n",
    "    \n",
    "    print(f'length of trainset: [{len(train)}]; len of holdout: [{len(holdout)}]')\n",
    "    \n",
    "    return train, holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make ds\n",
    "# pytorch datasets\n",
    "# n_train = n_holdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length of trainset: [12000]; len of holdout: [10000]\n"
     ]
    }
   ],
   "source": [
    "TFMS = transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize((0.1307,), (0.3081,))\n",
    "    ])\n",
    "\n",
    "train, holdout = get_dataset(TFMS, pct_cap=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(data: torch.utils.data.DataLoader, model: nn.Module): # phi\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in tqdm(data,total=len(data)):\n",
    "            images, labels = batch[0].to(DEVICE), batch[1]\n",
    "            outputs = model(images).cpu()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier Network Definition - SimpleConvNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 32, 3, 1)\n",
    "        self.conv2 = nn.Conv2d(32, 64, 3, 1)\n",
    "        self.dropout1 = nn.Dropout2d(0.25)\n",
    "        self.dropout2 = nn.Dropout2d(0.5)\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.conv2(x)\n",
    "        x = F.relu(x)\n",
    "        x = F.max_pool2d(x, 2)\n",
    "        x = self.dropout1(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.dropout2(x)\n",
    "        x = self.fc2(x)\n",
    "        output = F.log_softmax(x, dim=1)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = Classifier()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## AutoTrain Environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "45"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "REWIND_DIM = 3\n",
    "CLF_BS = 16\n",
    "SAMPLE = 50 # sampling interval\n",
    "BATCH_UPDATES = int(len(train) // CLF_BS * 0.5) # half an epoch\n",
    "LOSS_DIM = BATCH_UPDATES // SAMPLE\n",
    "(LOSS_DIM + 2 )* 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[time_step:0]  initialised backbone parameters & optimizer\n",
      "[time_step:0]  initialised phi value: started ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5fa1f51ebbc54c7c9290a5d2463a7980",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=750.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97573f7adf8041e0a3ba08eb1bfcc473",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=625.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[time_step:0]  initialised phi value: done\n",
      "[time_step:0]  added observation\n",
      "[time_step:0]  environment initialised : AutoTrainEnvironment with the following parameters:\n",
      "                        lr_init=0.0003, inter_reward=1, \n",
      "                        H=3, K=7, T=375\n"
     ]
    }
   ],
   "source": [
    "env = gym.make('AutoTrain-v0') # TODO loss func nll_loss\n",
    "\n",
    "ob = env.init(backbone=clf,  phi=accuracy, savedir=ENV_PATH,\n",
    "         trnds=train, valds=holdout,\n",
    "         T=BATCH_UPDATES, H=REWIND_DIM, S=SAMPLE, lr_init=3e-4, \n",
    "         inter_reward=1, final_reward_scale=100,\n",
    "         horizon=50, criterion=F.nll_loss,\n",
    "         num_workers=4, bs=CLF_BS, v=True, device=DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.observation_space_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.action_space_dim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Agent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agent Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up matplotlib\n",
    "\n",
    "is_ipython = 'inline' in matplotlib.get_backend()\n",
    "if is_ipython:\n",
    "    from IPython import display\n",
    "\n",
    "plt.ion()\n",
    "\n",
    "episode_durations = []\n",
    "\n",
    "def plot_durations():\n",
    "    plt.figure(2, figsize=(12,6))\n",
    "    plt.clf()\n",
    "    durations_t = torch.tensor(episode_durations, dtype=torch.float)\n",
    "    plt.title('Training...')\n",
    "    plt.xlabel('Episode')\n",
    "    plt.ylabel('Duration')\n",
    "    plt.plot(durations_t.numpy())\n",
    "    # Take 100 episode averages and plot them too\n",
    "    if len(durations_t) >= 100:\n",
    "        means = durations_t.unfold(0, 100, 1).mean(1).view(-1)\n",
    "        means = torch.cat((torch.zeros(99), means))\n",
    "        plt.plot(means.numpy())\n",
    "    if is_ipython:\n",
    "        display.clear_output(wait=True)\n",
    "        display.display(plt.gcf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[time_step:0]  initialised backbone parameters & optimizer\n",
      "[time_step:0]  initialised phi value: started ...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d1eb577491a44738b09bf0d397b253f6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=750.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3ec195b8d94b440a91aede126dd53355",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=625.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[time_step:0]  initialised phi value: done\n",
      "[time_step:0]  added observation\n",
      "[time_step:0]  environment initialised : AutoTrainEnvironment with the following parameters:\n",
      "                        lr_init=0.0003, inter_reward=1, \n",
      "                        H=3, K=7, T=375\n",
      "[ATA] exploration policy enacted\n",
      "[time_step:0]  action [1] received\n",
      "[time_step:0]  training loop started ...\n",
      "[time_step:1]  training loop done!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cbe5a5f9f8bf4276a97f981782f3a408",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=750.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4bd0cefc21ac4099bab8365554ad5686",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=625.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[time_step:1]  added observation\n",
      "[time_step:1]  reward at the end of time step is [1]\n",
      "[ATA episode 3]: took [6.6] seconds for one full step\n",
      "[ATA] exploration policy enacted\n",
      "[time_step:1]  action [5] received\n",
      "[time_step:1]  received RE-INIT signal\n",
      "[time_step:1]  initialised backbone parameters & optimizer\n",
      "[time_step:1]  training loop started ...\n",
      "[time_step:2]  training loop done!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bd6eeb2b15774360a32a494db84e5134",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=750.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3161d7f4dad74a75a808e39bb4b9963a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=625.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[time_step:2]  added observation\n",
      "[time_step:2]  reward at the end of time step is [1]\n",
      "[ATA] batch shapes: [torch.Size([16, 27]) torch.Size([16, 1]) torch.Size([16])]\n",
      "[ATA] DQN optimisation step complete \n",
      "[ATA episode 3]: took [6.4] seconds for one full step\n",
      "[ATA] exploration policy enacted\n",
      "[time_step:2]  action [0] received\n",
      "[time_step:2]  training loop started ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/tljh/user/lib/python3.7/site-packages/torch/nn/modules/container.py:100: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[time_step:3]  training loop done!\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8cd703db53554cefa3648b8c26c90a01",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=750.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ad20f2def8e48fd9ad778bf6b530648",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=625.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train an agent\n",
    "\n",
    "agent = AutoTrainAgent(env, DEVICE)\n",
    "\n",
    "num_episodes = 300\n",
    "for i_episode in range(num_episodes):\n",
    "    t = agent.episode(i_episode)\n",
    "    episode_durations.append(t + 1)\n",
    "    plot_durations()\n",
    "\n",
    "display.clear_output(wait=True)\n",
    "print('Complete')\n",
    "cpenv.env.render()\n",
    "cpenv.env.close()\n",
    "plt.ioff()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.logmdp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.observation_space_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
