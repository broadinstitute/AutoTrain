{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions.laplace import Laplace\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import  tqdm\n",
    "import seaborn as sns; sns.set()\n",
    "import pickle as pkl\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from functools import partial \n",
    "\n",
    "sns.set(rc={'figure.figsize':(15, 6)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:3\")\n",
    "DATA_ROOT = Path('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data & Model Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(transforms):\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root=DATA_ROOT / 'cifar-10-data', train=True,\n",
    "                                            download=True, transform=transforms)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root=DATA_ROOT / 'cifar-10-data', train=False,\n",
    "                                           download=True, transform=transforms)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=12,\n",
    "                                              shuffle=True, num_workers=2)\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=12,\n",
    "                                             shuffle=False, num_workers=2)\n",
    "    return trainloader, testloader\n",
    "\n",
    "\n",
    "CLASSES = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs = np.linspace(3e-4, 3e-3, num=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class StrongerConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(StrongerConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.conv3 = nn.Conv2d(16, 32, 5)\n",
    "        self.fc1 = nn.Linear(32 * 6 * 6, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256, 128)\n",
    "        self.fc4 = nn.Linear(128, 64)\n",
    "        self.fc5 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.relu(self.conv3(x))\n",
    "\n",
    "        x = x.view(-1, 32 * 6 * 6)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = F.relu(self.fc4(x))\n",
    "        x = self.fc5(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thresholdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Thresholdout:\n",
    "    def __init__(self, train, holdout, tolerance=0.01/4, scale_factor=4, keep_log=True):\n",
    "        self.tolerance = tolerance\n",
    "        \n",
    "        self.laplace_eps = Laplace(torch.tensor([0.0]), torch.tensor([2*self.tolerance]))\n",
    "        self.laplace_gamma = Laplace(torch.tensor([0.0]), torch.tensor([4*self.tolerance]))\n",
    "        self.laplace_eta = Laplace(torch.tensor([0.0]), torch.tensor([8*self.tolerance]))\n",
    "\n",
    "        self.train = train\n",
    "        self.holdout = holdout\n",
    "        \n",
    "        self.T = 4*tolerance + self.noise(self.laplace_gamma)\n",
    "        # self.budget = ???\n",
    "        \n",
    "        self.keep_log = keep_log\n",
    "        if keep_log:\n",
    "            self.log = pd.DataFrame(columns=['GlobStep', 'threshold', 'delta', 'phi_train', 'phi_holdout', 'estimate', 'overfit'])\n",
    "        \n",
    "        \n",
    "    def noise(self, dist):\n",
    "        return dist.sample().item()\n",
    "        \n",
    "    def verify_statistic(self, phi, glob_step=None):\n",
    "        \"\"\"\n",
    "            - phi(dataset) -> statistic: \n",
    "              function returns the average of some statistic\n",
    "        \"\"\"\n",
    "        \n",
    "        train_val = phi(self.train)\n",
    "        holdout_val = phi(self.holdout)\n",
    "                \n",
    "        delta = abs(train_val - holdout_val)\n",
    "        thresh = self.T + self.noise(self.laplace_eta)\n",
    "        \n",
    "        if delta > thresh:\n",
    "            self.T += self.noise(self.laplace_gamma)\n",
    "            estimate = holdout_val + self.noise(self.laplace_eps)\n",
    "        else:\n",
    "            estimate = train_val\n",
    "            \n",
    "        if self.keep_log:\n",
    "            if glob_step is None: \n",
    "                raise ValueException('please provide glob step if logging is on')\n",
    "            self.log.loc[len(self.log)] = [glob_step, thresh, delta, train_val, holdout_val, estimate, delta > thresh]\n",
    "            \n",
    "        return estimate\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(model, data_loader): \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            images, labels = data[0].to(DEVICE), data[1]\n",
    "            outputs = model(images).cpu()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, lr, epochs=10, sample_step=500 ):\n",
    "    \n",
    "    trainloader, testloader = data\n",
    "    tout = Thresholdout(trainloader, testloader, keep_log=True)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "    loss_history = []\n",
    "    glob_step = 0\n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data[0].to(DEVICE), data[1].to(DEVICE)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            loss_history += [loss.item()]\n",
    "            glob_step += 1\n",
    "            \n",
    "            if i % sample_step == 0 and i:\n",
    "                acc_val = tout.verify_statistic(partial(test_accuracy, model), glob_step)\n",
    "                print(f'[{epoch+1}, step::{i}] loss [{running_loss / sample_step :.3f}] accuracy [{acc_val:.3f}]')\n",
    "                running_loss = 0.0\n",
    "                \n",
    "    return loss_history, tout\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "conv_transform = T.Compose([T.ToTensor(), T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "conv_data = make_data(conv_transform)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------- [LR: [0.0003]] ------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "548a38b73f35485f83e5963efd0d5595",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, step::500] loss [2.104] accuracy [0.182]\n",
      "[1, step::1000] loss [1.958] accuracy [0.218]\n",
      "[1, step::1500] loss [1.845] accuracy [0.318]\n",
      "[1, step::2000] loss [1.763] accuracy [0.364]\n",
      "[1, step::2500] loss [1.671] accuracy [0.361]\n",
      "[1, step::3000] loss [1.652] accuracy [0.401]\n",
      "[1, step::3500] loss [1.592] accuracy [0.419]\n",
      "[1, step::4000] loss [1.580] accuracy [0.419]\n",
      "[2, step::500] loss [1.534] accuracy [0.421]\n",
      "[2, step::1000] loss [1.521] accuracy [0.435]\n",
      "[2, step::1500] loss [1.477] accuracy [0.452]\n",
      "[2, step::2000] loss [1.445] accuracy [0.466]\n",
      "[2, step::2500] loss [1.487] accuracy [0.470]\n",
      "[2, step::3000] loss [1.422] accuracy [0.465]\n",
      "[2, step::3500] loss [1.434] accuracy [0.487]\n",
      "[2, step::4000] loss [1.424] accuracy [0.455]\n",
      "[3, step::500] loss [1.383] accuracy [0.497]\n",
      "[3, step::1000] loss [1.346] accuracy [0.506]\n",
      "[3, step::1500] loss [1.340] accuracy [0.501]\n",
      "[3, step::2000] loss [1.335] accuracy [0.501]\n",
      "[3, step::2500] loss [1.303] accuracy [0.519]\n",
      "[3, step::3000] loss [1.309] accuracy [0.526]\n",
      "[3, step::3500] loss [1.298] accuracy [0.508]\n",
      "[3, step::4000] loss [1.283] accuracy [0.530]\n",
      "[4, step::500] loss [1.244] accuracy [0.536]\n",
      "[4, step::1000] loss [1.226] accuracy [0.550]\n",
      "[4, step::1500] loss [1.226] accuracy [0.551]\n",
      "[4, step::2000] loss [1.226] accuracy [0.553]\n",
      "[4, step::2500] loss [1.204] accuracy [0.545]\n",
      "[4, step::3000] loss [1.206] accuracy [0.569]\n",
      "[4, step::3500] loss [1.211] accuracy [0.555]\n",
      "[4, step::4000] loss [1.205] accuracy [0.554]\n",
      "[5, step::500] loss [1.160] accuracy [0.565]\n",
      "[5, step::1000] loss [1.132] accuracy [0.552]\n",
      "[5, step::1500] loss [1.131] accuracy [0.578]\n",
      "[5, step::2000] loss [1.110] accuracy [0.572]\n",
      "[5, step::2500] loss [1.139] accuracy [0.565]\n",
      "[5, step::3000] loss [1.135] accuracy [0.574]\n",
      "[5, step::3500] loss [1.090] accuracy [0.585]\n",
      "[5, step::4000] loss [1.139] accuracy [0.579]\n",
      "[6, step::500] loss [1.049] accuracy [0.585]\n",
      "[6, step::1000] loss [1.071] accuracy [0.590]\n",
      "[6, step::1500] loss [1.052] accuracy [0.594]\n",
      "[6, step::2000] loss [1.039] accuracy [0.568]\n",
      "[6, step::2500] loss [1.058] accuracy [0.592]\n",
      "[6, step::3000] loss [1.045] accuracy [0.591]\n",
      "[6, step::3500] loss [1.032] accuracy [0.581]\n",
      "[6, step::4000] loss [1.033] accuracy [0.601]\n",
      "[7, step::500] loss [0.982] accuracy [0.612]\n",
      "[7, step::1000] loss [0.957] accuracy [0.590]\n",
      "[7, step::1500] loss [0.968] accuracy [0.598]\n",
      "[7, step::2000] loss [0.991] accuracy [0.598]\n",
      "[7, step::2500] loss [0.977] accuracy [0.606]\n",
      "[7, step::3000] loss [0.985] accuracy [0.599]\n",
      "[7, step::3500] loss [0.969] accuracy [0.594]\n",
      "[7, step::4000] loss [0.951] accuracy [0.619]\n",
      "[8, step::500] loss [0.883] accuracy [0.613]\n",
      "[8, step::1000] loss [0.860] accuracy [0.603]\n",
      "[8, step::1500] loss [0.885] accuracy [0.607]\n",
      "[8, step::2000] loss [0.903] accuracy [0.616]\n",
      "[8, step::2500] loss [0.916] accuracy [0.618]\n",
      "[8, step::3000] loss [0.888] accuracy [0.610]\n",
      "[8, step::3500] loss [0.910] accuracy [0.612]\n",
      "[8, step::4000] loss [0.912] accuracy [0.606]\n",
      "[9, step::500] loss [0.792] accuracy [0.603]\n",
      "[9, step::1000] loss [0.809] accuracy [0.613]\n",
      "[9, step::1500] loss [0.815] accuracy [0.618]\n",
      "[9, step::2000] loss [0.818] accuracy [0.618]\n",
      "[9, step::2500] loss [0.842] accuracy [0.608]\n",
      "[9, step::3000] loss [0.832] accuracy [0.608]\n",
      "[9, step::3500] loss [0.824] accuracy [0.614]\n",
      "[9, step::4000] loss [0.844] accuracy [0.619]\n",
      "[10, step::500] loss [0.738] accuracy [0.616]\n",
      "[10, step::1000] loss [0.700] accuracy [0.617]\n",
      "[10, step::1500] loss [0.727] accuracy [0.607]\n",
      "[10, step::2000] loss [0.751] accuracy [0.614]\n",
      "[10, step::2500] loss [0.732] accuracy [0.609]\n",
      "[10, step::3000] loss [0.756] accuracy [0.635]\n",
      "[10, step::3500] loss [0.755] accuracy [0.628]\n",
      "[10, step::4000] loss [0.755] accuracy [0.625]\n",
      "\n",
      "--------- [LR: [0.0006000000000000001]] ------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff56e6ab46c74c9183009715b8bb70ab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, step::500] loss [2.067] accuracy [0.216]\n",
      "[1, step::1000] loss [1.889] accuracy [0.280]\n",
      "[1, step::1500] loss [1.778] accuracy [0.332]\n",
      "[1, step::2000] loss [1.708] accuracy [0.353]\n",
      "[1, step::2500] loss [1.649] accuracy [0.382]\n",
      "[1, step::3000] loss [1.589] accuracy [0.418]\n",
      "[1, step::3500] loss [1.544] accuracy [0.440]\n",
      "[1, step::4000] loss [1.531] accuracy [0.446]\n",
      "[2, step::500] loss [1.483] accuracy [0.448]\n",
      "[2, step::1000] loss [1.470] accuracy [0.470]\n",
      "[2, step::1500] loss [1.450] accuracy [0.446]\n",
      "[2, step::2000] loss [1.421] accuracy [0.494]\n",
      "[2, step::2500] loss [1.433] accuracy [0.511]\n",
      "[2, step::3000] loss [1.406] accuracy [0.511]\n",
      "[2, step::3500] loss [1.359] accuracy [0.522]\n",
      "[2, step::4000] loss [1.345] accuracy [0.535]\n",
      "[3, step::500] loss [1.305] accuracy [0.549]\n",
      "[3, step::1000] loss [1.282] accuracy [0.535]\n",
      "[3, step::1500] loss [1.295] accuracy [0.560]\n",
      "[3, step::2000] loss [1.273] accuracy [0.559]\n",
      "[3, step::2500] loss [1.284] accuracy [0.567]\n",
      "[3, step::3000] loss [1.266] accuracy [0.545]\n",
      "[3, step::3500] loss [1.251] accuracy [0.540]\n",
      "[3, step::4000] loss [1.248] accuracy [0.564]\n",
      "[4, step::500] loss [1.169] accuracy [0.551]\n",
      "[4, step::1000] loss [1.161] accuracy [0.604]\n",
      "[4, step::1500] loss [1.174] accuracy [0.547]\n",
      "[4, step::2000] loss [1.185] accuracy [0.570]\n",
      "[4, step::2500] loss [1.166] accuracy [0.566]\n",
      "[4, step::3000] loss [1.167] accuracy [0.607]\n",
      "[4, step::3500] loss [1.171] accuracy [0.581]\n",
      "[4, step::4000] loss [1.161] accuracy [0.584]\n",
      "[5, step::500] loss [1.080] accuracy [0.560]\n",
      "[5, step::1000] loss [1.087] accuracy [0.579]\n",
      "[5, step::1500] loss [1.107] accuracy [0.577]\n",
      "[5, step::2000] loss [1.077] accuracy [0.631]\n",
      "[5, step::2500] loss [1.079] accuracy [0.592]\n",
      "[5, step::3000] loss [1.085] accuracy [0.577]\n",
      "[5, step::3500] loss [1.089] accuracy [0.591]\n",
      "[5, step::4000] loss [1.063] accuracy [0.590]\n",
      "[6, step::500] loss [0.992] accuracy [0.600]\n",
      "[6, step::1000] loss [0.989] accuracy [0.581]\n",
      "[6, step::1500] loss [1.021] accuracy [0.598]\n",
      "[6, step::2000] loss [1.009] accuracy [0.603]\n",
      "[6, step::2500] loss [0.999] accuracy [0.598]\n",
      "[6, step::3000] loss [1.010] accuracy [0.594]\n",
      "[6, step::3500] loss [0.995] accuracy [0.591]\n",
      "[6, step::4000] loss [1.034] accuracy [0.611]\n",
      "[7, step::500] loss [0.904] accuracy [0.603]\n",
      "[7, step::1000] loss [0.909] accuracy [0.588]\n",
      "[7, step::1500] loss [0.920] accuracy [0.596]\n",
      "[7, step::2000] loss [0.938] accuracy [0.599]\n",
      "[7, step::2500] loss [0.918] accuracy [0.605]\n",
      "[7, step::3000] loss [0.906] accuracy [0.611]\n",
      "[7, step::3500] loss [0.938] accuracy [0.582]\n",
      "[7, step::4000] loss [0.936] accuracy [0.612]\n",
      "[8, step::500] loss [0.828] accuracy [0.609]\n",
      "[8, step::1000] loss [0.831] accuracy [0.603]\n",
      "[8, step::1500] loss [0.839] accuracy [0.594]\n",
      "[8, step::2000] loss [0.843] accuracy [0.597]\n",
      "[8, step::2500] loss [0.831] accuracy [0.615]\n",
      "[8, step::3000] loss [0.862] accuracy [0.736]\n",
      "[8, step::3500] loss [0.861] accuracy [0.732]\n",
      "[8, step::4000] loss [0.884] accuracy [0.608]\n",
      "[9, step::500] loss [0.710] accuracy [0.603]\n",
      "[9, step::1000] loss [0.750] accuracy [0.604]\n",
      "[9, step::1500] loss [0.754] accuracy [0.608]\n",
      "[9, step::2000] loss [0.776] accuracy [0.738]\n",
      "[9, step::2500] loss [0.746] accuracy [0.764]\n",
      "[9, step::3000] loss [0.779] accuracy [0.604]\n",
      "[9, step::3500] loss [0.785] accuracy [0.601]\n",
      "[9, step::4000] loss [0.770] accuracy [0.589]\n",
      "[10, step::500] loss [0.628] accuracy [0.603]\n",
      "[10, step::1000] loss [0.671] accuracy [0.591]\n",
      "[10, step::1500] loss [0.680] accuracy [0.607]\n",
      "[10, step::2000] loss [0.654] accuracy [0.599]\n",
      "[10, step::2500] loss [0.659] accuracy [0.600]\n",
      "[10, step::3000] loss [0.715] accuracy [0.605]\n",
      "[10, step::3500] loss [0.697] accuracy [0.624]\n",
      "[10, step::4000] loss [0.709] accuracy [0.601]\n",
      "\n",
      "--------- [LR: [0.0009]] ------------\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a8959e35b3b423a8a974f4ae1a24dc1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, step::500] loss [2.098] accuracy [0.194]\n",
      "[1, step::1000] loss [1.948] accuracy [0.233]\n",
      "[1, step::1500] loss [1.884] accuracy [0.268]\n",
      "[1, step::2000] loss [1.819] accuracy [0.304]\n",
      "[1, step::2500] loss [1.708] accuracy [0.394]\n",
      "[1, step::3000] loss [1.661] accuracy [0.396]\n",
      "[1, step::3500] loss [1.587] accuracy [0.408]\n",
      "[1, step::4000] loss [1.557] accuracy [0.410]\n",
      "[2, step::500] loss [1.506] accuracy [0.444]\n",
      "[2, step::1000] loss [1.487] accuracy [0.478]\n",
      "[2, step::1500] loss [1.426] accuracy [0.452]\n",
      "[2, step::2000] loss [1.424] accuracy [0.489]\n",
      "[2, step::2500] loss [1.419] accuracy [0.485]\n",
      "[2, step::3000] loss [1.423] accuracy [0.481]\n",
      "[2, step::3500] loss [1.395] accuracy [0.477]\n",
      "[2, step::4000] loss [1.384] accuracy [0.496]\n",
      "[3, step::500] loss [1.336] accuracy [0.512]\n",
      "[3, step::1000] loss [1.317] accuracy [0.496]\n",
      "[3, step::1500] loss [1.308] accuracy [0.520]\n",
      "[3, step::2000] loss [1.319] accuracy [0.516]\n",
      "[3, step::2500] loss [1.275] accuracy [0.521]\n",
      "[3, step::3000] loss [1.304] accuracy [0.512]\n",
      "[3, step::3500] loss [1.284] accuracy [0.531]\n",
      "[3, step::4000] loss [1.284] accuracy [0.504]\n",
      "[4, step::500] loss [1.210] accuracy [0.548]\n",
      "[4, step::1000] loss [1.230] accuracy [0.562]\n",
      "[4, step::1500] loss [1.233] accuracy [0.534]\n",
      "[4, step::2000] loss [1.198] accuracy [0.546]\n",
      "[4, step::2500] loss [1.209] accuracy [0.547]\n",
      "[4, step::3000] loss [1.213] accuracy [0.527]\n",
      "[4, step::3500] loss [1.202] accuracy [0.530]\n",
      "[4, step::4000] loss [1.223] accuracy [0.562]\n",
      "[5, step::500] loss [1.137] accuracy [0.553]\n",
      "[5, step::1000] loss [1.115] accuracy [0.602]\n",
      "[5, step::1500] loss [1.139] accuracy [0.556]\n",
      "[5, step::2000] loss [1.147] accuracy [0.570]\n"
     ]
    }
   ],
   "source": [
    "results = dict()\n",
    "for lr in lrs:\n",
    "    print(f'--------- [LR: [{lr}]] ------------')\n",
    "    convnet = StrongerConvNet()\n",
    "    convnet.to(DEVICE)\n",
    "    \n",
    "    results[lr] = train(convnet, conv_data, lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('convnet-lr-outcome.pkl','wb') as fp:\n",
    "    pkl.dump(results, fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
