{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as T\n",
    "import torchvision.models as models\n",
    "\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.distributions.laplace import Laplace\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm.notebook import  tqdm\n",
    "import seaborn as sns; sns.set()\n",
    "import pickle as pkl\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from functools import partial \n",
    "\n",
    "sns.set(rc={'figure.figsize':(15, 6)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:3\")\n",
    "DATA_ROOT = Path('../data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data & Model Prep"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_data(transforms):\n",
    "\n",
    "    trainset = torchvision.datasets.CIFAR10(root=DATA_ROOT / 'cifar-10-data', train=True,\n",
    "                                            download=True, transform=transforms)\n",
    "\n",
    "    testset = torchvision.datasets.CIFAR10(root=DATA_ROOT / 'cifar-10-data', train=False,\n",
    "                                           download=True, transform=transforms)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, batch_size=16,\n",
    "                                              shuffle=True, num_workers=2)\n",
    "\n",
    "    testloader = torch.utils.data.DataLoader(testset, batch_size=16,\n",
    "                                             shuffle=False, num_workers=2)\n",
    "    return trainloader, testloader\n",
    "\n",
    "\n",
    "CLASSES = ('plane', 'car', 'bird', 'cat',\n",
    "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ConvNet(\n",
       "  (conv1): Conv2d(3, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
       "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(ConvNet, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(3, 6, 5)\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(F.relu(self.conv1(x)))\n",
    "        x = self.pool(F.relu(self.conv2(x)))\n",
    "        x = x.view(-1, 16 * 5 * 5)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "convnet = ConvNet()\n",
    "convnet.to(DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thresholdout"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Thresholdout:\n",
    "    def __init__(self, train, holdout, tolerance=0.01/4, scale_factor=4, keep_log=True):\n",
    "        self.tolerance = tolerance\n",
    "        \n",
    "        self.laplace_eps = Laplace(torch.tensor([0.0]), torch.tensor([2*self.tolerance]))\n",
    "        self.laplace_gamma = Laplace(torch.tensor([0.0]), torch.tensor([4*self.tolerance]))\n",
    "        self.laplace_eta = Laplace(torch.tensor([0.0]), torch.tensor([8*self.tolerance]))\n",
    "\n",
    "        self.train = train\n",
    "        self.holdout = holdout\n",
    "        \n",
    "        self.T = 4*tolerance + self.noise(self.laplace_gamma)\n",
    "        # self.budget = ???\n",
    "        \n",
    "        self.keep_log = keep_log\n",
    "        if keep_log:\n",
    "            self.log = pd.DataFrame(columns=['GlobStep', 'threshold', 'delta', 'phi_train', 'phi_holdout', 'estimate', 'overfit'])\n",
    "        \n",
    "        \n",
    "    def noise(self, dist):\n",
    "        return dist.sample().item()\n",
    "        \n",
    "    def verify_statistic(self, phi, glob_step=None):\n",
    "        \"\"\"\n",
    "            - phi(dataset) -> statistic: \n",
    "              function returns the average of some statistic\n",
    "        \"\"\"\n",
    "        \n",
    "        train_val = phi(self.train)\n",
    "        holdout_val = phi(self.holdout)\n",
    "                \n",
    "        delta = abs(train_val - holdout_val)\n",
    "        thresh = self.T + self.noise(self.laplace_eta)\n",
    "        \n",
    "        if delta > thresh:\n",
    "            self.T += self.noise(self.laplace_gamma)\n",
    "            estimate = holdout_val + self.noise(self.laplace_eps)\n",
    "        else:\n",
    "            estimate = train_val\n",
    "            \n",
    "        if self.keep_log:\n",
    "            if glob_step is None: \n",
    "                raise ValueException('please provide glob step if logging is on')\n",
    "            self.log.loc[len(self.log)] = [glob_step, thresh, delta, train_val, holdout_val, estimate, delta > thresh]\n",
    "            \n",
    "        return estimate\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_accuracy(model, data_loader): \n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for data in data_loader:\n",
    "            images, labels = data[0].to(DEVICE), data[1]\n",
    "            outputs = model(images).cpu()\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "    return correct / total"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, data, epochs=20, sample_step=1000):\n",
    "    \n",
    "    trainloader, testloader = data\n",
    "    tout = Thresholdout(trainloader, testloader, keep_log=True)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=3e-4)\n",
    "    \n",
    "    loss_history = []\n",
    "    glob_step = 0\n",
    "    \n",
    "    for epoch in tqdm(range(epochs)):  # loop over the dataset multiple times\n",
    "\n",
    "        running_loss = 0.0\n",
    "\n",
    "        for i, data in enumerate(trainloader, 0):\n",
    "            # get the inputs; data is a list of [inputs, labels]\n",
    "            inputs, labels = data[0].to(DEVICE), data[1].to(DEVICE)\n",
    "\n",
    "            # zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "            loss_history += [loss.item()]\n",
    "            glob_step += 1\n",
    "            \n",
    "            if i % sample_step == 0 and i:\n",
    "                acc_val = tout.verify_statistic(partial(test_accuracy, model), glob_step)\n",
    "                print(f'[{epoch+1}, step::{i}] loss [{running_loss / sample_step :.3f}] accuracy [{acc_val:.3f}]')\n",
    "                running_loss = 0.0\n",
    "                \n",
    "    return loss_history, tout\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2744c12f97204911b312c949e95ab0ac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=20.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, step::1000] loss [1.878] accuracy [0.383]\n",
      "[1, step::2000] loss [1.613] accuracy [0.434]\n",
      "[1, step::3000] loss [1.531] accuracy [0.464]\n",
      "[2, step::1000] loss [1.442] accuracy [0.482]\n",
      "[2, step::2000] loss [1.413] accuracy [0.489]\n",
      "[2, step::3000] loss [1.374] accuracy [0.510]\n",
      "[3, step::1000] loss [1.305] accuracy [0.528]\n",
      "[3, step::2000] loss [1.291] accuracy [0.550]\n",
      "[3, step::3000] loss [1.275] accuracy [0.541]\n",
      "[4, step::1000] loss [1.220] accuracy [0.538]\n",
      "[4, step::2000] loss [1.200] accuracy [0.577]\n",
      "[4, step::3000] loss [1.201] accuracy [0.558]\n",
      "[5, step::1000] loss [1.161] accuracy [0.580]\n",
      "[5, step::2000] loss [1.150] accuracy [0.580]\n",
      "[5, step::3000] loss [1.119] accuracy [0.594]\n",
      "[6, step::1000] loss [1.101] accuracy [0.572]\n",
      "[6, step::2000] loss [1.083] accuracy [0.591]\n",
      "[6, step::3000] loss [1.083] accuracy [0.589]\n",
      "[7, step::1000] loss [1.039] accuracy [0.603]\n",
      "[7, step::2000] loss [1.054] accuracy [0.584]\n",
      "[7, step::3000] loss [1.038] accuracy [0.621]\n",
      "[8, step::1000] loss [1.011] accuracy [0.613]\n",
      "[8, step::2000] loss [0.996] accuracy [0.609]\n",
      "[8, step::3000] loss [0.999] accuracy [0.603]\n",
      "[9, step::1000] loss [0.959] accuracy [0.617]\n",
      "[9, step::2000] loss [0.959] accuracy [0.617]\n",
      "[9, step::3000] loss [0.964] accuracy [0.624]\n",
      "[10, step::1000] loss [0.913] accuracy [0.613]\n",
      "[10, step::2000] loss [0.930] accuracy [0.621]\n",
      "[10, step::3000] loss [0.949] accuracy [0.610]\n",
      "[11, step::1000] loss [0.885] accuracy [0.620]\n",
      "[11, step::2000] loss [0.901] accuracy [0.619]\n",
      "[11, step::3000] loss [0.908] accuracy [0.615]\n",
      "[12, step::1000] loss [0.869] accuracy [0.636]\n",
      "[12, step::2000] loss [0.854] accuracy [0.626]\n",
      "[12, step::3000] loss [0.883] accuracy [0.653]\n",
      "[13, step::1000] loss [0.829] accuracy [0.637]\n",
      "[13, step::2000] loss [0.848] accuracy [0.628]\n",
      "[13, step::3000] loss [0.855] accuracy [0.628]\n",
      "[14, step::1000] loss [0.810] accuracy [0.644]\n",
      "[14, step::2000] loss [0.819] accuracy [0.632]\n",
      "[14, step::3000] loss [0.824] accuracy [0.620]\n",
      "[15, step::1000] loss [0.784] accuracy [0.633]\n",
      "[15, step::2000] loss [0.781] accuracy [0.631]\n",
      "[15, step::3000] loss [0.805] accuracy [0.629]\n",
      "[16, step::1000] loss [0.755] accuracy [0.640]\n",
      "[16, step::2000] loss [0.772] accuracy [0.640]\n",
      "[16, step::3000] loss [0.775] accuracy [0.636]\n",
      "[17, step::1000] loss [0.741] accuracy [0.649]\n",
      "[17, step::2000] loss [0.740] accuracy [0.640]\n",
      "[17, step::3000] loss [0.747] accuracy [0.634]\n",
      "[18, step::1000] loss [0.717] accuracy [0.639]\n",
      "[18, step::2000] loss [0.717] accuracy [0.636]\n",
      "[18, step::3000] loss [0.738] accuracy [0.637]\n",
      "[19, step::1000] loss [0.677] accuracy [0.637]\n",
      "[19, step::2000] loss [0.709] accuracy [0.648]\n",
      "[19, step::3000] loss [0.725] accuracy [0.639]\n",
      "[20, step::1000] loss [0.661] accuracy [0.646]\n",
      "[20, step::2000] loss [0.691] accuracy [0.638]\n",
      "[20, step::3000] loss [0.694] accuracy [0.632]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "conv_transform = T.Compose([T.ToTensor(), T.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
    "conv_data = make_data(conv_transform)\n",
    "conv_history, convtout = train(convnet, conv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('convnet-outcome.pkl','wb') as fp:\n",
    "    pkl.dump((conv_history, convtout), fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = convtout.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GlobStep</th>\n",
       "      <th>threshold</th>\n",
       "      <th>delta</th>\n",
       "      <th>phi_train</th>\n",
       "      <th>phi_holdout</th>\n",
       "      <th>estimate</th>\n",
       "      <th>overfit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001</td>\n",
       "      <td>0.023347</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.38264</td>\n",
       "      <td>0.3826</td>\n",
       "      <td>0.382640</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001</td>\n",
       "      <td>-0.021424</td>\n",
       "      <td>0.00400</td>\n",
       "      <td>0.43760</td>\n",
       "      <td>0.4336</td>\n",
       "      <td>0.433547</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3001</td>\n",
       "      <td>-0.011971</td>\n",
       "      <td>0.00110</td>\n",
       "      <td>0.46220</td>\n",
       "      <td>0.4611</td>\n",
       "      <td>0.464234</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4126</td>\n",
       "      <td>-0.026733</td>\n",
       "      <td>0.00036</td>\n",
       "      <td>0.48314</td>\n",
       "      <td>0.4835</td>\n",
       "      <td>0.481943</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5126</td>\n",
       "      <td>-0.008287</td>\n",
       "      <td>0.00862</td>\n",
       "      <td>0.50972</td>\n",
       "      <td>0.5011</td>\n",
       "      <td>0.488755</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6126</td>\n",
       "      <td>-0.017283</td>\n",
       "      <td>0.01208</td>\n",
       "      <td>0.51908</td>\n",
       "      <td>0.5070</td>\n",
       "      <td>0.509735</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7251</td>\n",
       "      <td>-0.100606</td>\n",
       "      <td>0.00832</td>\n",
       "      <td>0.53922</td>\n",
       "      <td>0.5309</td>\n",
       "      <td>0.528483</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8251</td>\n",
       "      <td>-0.034976</td>\n",
       "      <td>0.01736</td>\n",
       "      <td>0.55686</td>\n",
       "      <td>0.5395</td>\n",
       "      <td>0.550288</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9251</td>\n",
       "      <td>-0.106600</td>\n",
       "      <td>0.01894</td>\n",
       "      <td>0.55994</td>\n",
       "      <td>0.5410</td>\n",
       "      <td>0.541197</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10376</td>\n",
       "      <td>0.008021</td>\n",
       "      <td>0.02036</td>\n",
       "      <td>0.56206</td>\n",
       "      <td>0.5417</td>\n",
       "      <td>0.537625</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11376</td>\n",
       "      <td>0.015296</td>\n",
       "      <td>0.01414</td>\n",
       "      <td>0.57724</td>\n",
       "      <td>0.5631</td>\n",
       "      <td>0.577240</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12376</td>\n",
       "      <td>-0.033169</td>\n",
       "      <td>0.02284</td>\n",
       "      <td>0.58604</td>\n",
       "      <td>0.5632</td>\n",
       "      <td>0.558417</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13501</td>\n",
       "      <td>-0.042710</td>\n",
       "      <td>0.02544</td>\n",
       "      <td>0.60204</td>\n",
       "      <td>0.5766</td>\n",
       "      <td>0.580373</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14501</td>\n",
       "      <td>-0.054156</td>\n",
       "      <td>0.02876</td>\n",
       "      <td>0.61136</td>\n",
       "      <td>0.5826</td>\n",
       "      <td>0.580223</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15501</td>\n",
       "      <td>-0.072477</td>\n",
       "      <td>0.02776</td>\n",
       "      <td>0.61116</td>\n",
       "      <td>0.5834</td>\n",
       "      <td>0.594310</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16626</td>\n",
       "      <td>0.008199</td>\n",
       "      <td>0.03006</td>\n",
       "      <td>0.60256</td>\n",
       "      <td>0.5725</td>\n",
       "      <td>0.572032</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17626</td>\n",
       "      <td>0.000888</td>\n",
       "      <td>0.03610</td>\n",
       "      <td>0.62570</td>\n",
       "      <td>0.5896</td>\n",
       "      <td>0.591406</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18626</td>\n",
       "      <td>0.000811</td>\n",
       "      <td>0.03606</td>\n",
       "      <td>0.62926</td>\n",
       "      <td>0.5932</td>\n",
       "      <td>0.588872</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19751</td>\n",
       "      <td>-0.032127</td>\n",
       "      <td>0.04130</td>\n",
       "      <td>0.63730</td>\n",
       "      <td>0.5960</td>\n",
       "      <td>0.603133</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20751</td>\n",
       "      <td>-0.069270</td>\n",
       "      <td>0.03540</td>\n",
       "      <td>0.62530</td>\n",
       "      <td>0.5899</td>\n",
       "      <td>0.583996</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21751</td>\n",
       "      <td>-0.084952</td>\n",
       "      <td>0.04752</td>\n",
       "      <td>0.65192</td>\n",
       "      <td>0.6044</td>\n",
       "      <td>0.621472</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22876</td>\n",
       "      <td>-0.070324</td>\n",
       "      <td>0.04204</td>\n",
       "      <td>0.64694</td>\n",
       "      <td>0.6049</td>\n",
       "      <td>0.612654</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23876</td>\n",
       "      <td>-0.064011</td>\n",
       "      <td>0.05004</td>\n",
       "      <td>0.66074</td>\n",
       "      <td>0.6107</td>\n",
       "      <td>0.608580</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24876</td>\n",
       "      <td>-0.066550</td>\n",
       "      <td>0.05082</td>\n",
       "      <td>0.65352</td>\n",
       "      <td>0.6027</td>\n",
       "      <td>0.603315</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>26001</td>\n",
       "      <td>-0.082448</td>\n",
       "      <td>0.05770</td>\n",
       "      <td>0.67090</td>\n",
       "      <td>0.6132</td>\n",
       "      <td>0.616852</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>27001</td>\n",
       "      <td>-0.111417</td>\n",
       "      <td>0.05942</td>\n",
       "      <td>0.67452</td>\n",
       "      <td>0.6151</td>\n",
       "      <td>0.616552</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>28001</td>\n",
       "      <td>-0.086038</td>\n",
       "      <td>0.06304</td>\n",
       "      <td>0.68314</td>\n",
       "      <td>0.6201</td>\n",
       "      <td>0.624494</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>29126</td>\n",
       "      <td>-0.082388</td>\n",
       "      <td>0.06670</td>\n",
       "      <td>0.68260</td>\n",
       "      <td>0.6159</td>\n",
       "      <td>0.612540</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>30126</td>\n",
       "      <td>-0.082147</td>\n",
       "      <td>0.06094</td>\n",
       "      <td>0.68364</td>\n",
       "      <td>0.6227</td>\n",
       "      <td>0.621344</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>31126</td>\n",
       "      <td>-0.100681</td>\n",
       "      <td>0.06270</td>\n",
       "      <td>0.67670</td>\n",
       "      <td>0.6140</td>\n",
       "      <td>0.610193</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>32251</td>\n",
       "      <td>-0.041823</td>\n",
       "      <td>0.07106</td>\n",
       "      <td>0.69126</td>\n",
       "      <td>0.6202</td>\n",
       "      <td>0.620147</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>33251</td>\n",
       "      <td>-0.060448</td>\n",
       "      <td>0.06856</td>\n",
       "      <td>0.69256</td>\n",
       "      <td>0.6240</td>\n",
       "      <td>0.619226</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>34251</td>\n",
       "      <td>-0.165596</td>\n",
       "      <td>0.07464</td>\n",
       "      <td>0.70334</td>\n",
       "      <td>0.6287</td>\n",
       "      <td>0.615211</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>35376</td>\n",
       "      <td>-0.118861</td>\n",
       "      <td>0.07672</td>\n",
       "      <td>0.70432</td>\n",
       "      <td>0.6276</td>\n",
       "      <td>0.636081</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>36376</td>\n",
       "      <td>-0.095016</td>\n",
       "      <td>0.07700</td>\n",
       "      <td>0.70170</td>\n",
       "      <td>0.6247</td>\n",
       "      <td>0.625781</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>37376</td>\n",
       "      <td>-0.100465</td>\n",
       "      <td>0.08012</td>\n",
       "      <td>0.71242</td>\n",
       "      <td>0.6323</td>\n",
       "      <td>0.653423</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>38501</td>\n",
       "      <td>-0.119056</td>\n",
       "      <td>0.08180</td>\n",
       "      <td>0.71390</td>\n",
       "      <td>0.6321</td>\n",
       "      <td>0.636874</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>39501</td>\n",
       "      <td>-0.112550</td>\n",
       "      <td>0.08682</td>\n",
       "      <td>0.71922</td>\n",
       "      <td>0.6324</td>\n",
       "      <td>0.627593</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>40501</td>\n",
       "      <td>-0.190731</td>\n",
       "      <td>0.08598</td>\n",
       "      <td>0.71608</td>\n",
       "      <td>0.6301</td>\n",
       "      <td>0.627631</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>41626</td>\n",
       "      <td>-0.084703</td>\n",
       "      <td>0.09154</td>\n",
       "      <td>0.73394</td>\n",
       "      <td>0.6424</td>\n",
       "      <td>0.644270</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>42626</td>\n",
       "      <td>-0.145958</td>\n",
       "      <td>0.09758</td>\n",
       "      <td>0.72828</td>\n",
       "      <td>0.6307</td>\n",
       "      <td>0.631599</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>43626</td>\n",
       "      <td>-0.153081</td>\n",
       "      <td>0.09062</td>\n",
       "      <td>0.71432</td>\n",
       "      <td>0.6237</td>\n",
       "      <td>0.619774</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>44751</td>\n",
       "      <td>-0.167272</td>\n",
       "      <td>0.09378</td>\n",
       "      <td>0.72518</td>\n",
       "      <td>0.6314</td>\n",
       "      <td>0.632698</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>45751</td>\n",
       "      <td>-0.093294</td>\n",
       "      <td>0.10268</td>\n",
       "      <td>0.73338</td>\n",
       "      <td>0.6307</td>\n",
       "      <td>0.630583</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>46751</td>\n",
       "      <td>-0.155555</td>\n",
       "      <td>0.10058</td>\n",
       "      <td>0.72918</td>\n",
       "      <td>0.6286</td>\n",
       "      <td>0.629465</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>47876</td>\n",
       "      <td>-0.175936</td>\n",
       "      <td>0.10834</td>\n",
       "      <td>0.74894</td>\n",
       "      <td>0.6406</td>\n",
       "      <td>0.640239</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>48876</td>\n",
       "      <td>-0.189163</td>\n",
       "      <td>0.10980</td>\n",
       "      <td>0.74340</td>\n",
       "      <td>0.6336</td>\n",
       "      <td>0.639568</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>49876</td>\n",
       "      <td>-0.197798</td>\n",
       "      <td>0.10550</td>\n",
       "      <td>0.73890</td>\n",
       "      <td>0.6334</td>\n",
       "      <td>0.635885</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>51001</td>\n",
       "      <td>-0.142781</td>\n",
       "      <td>0.11904</td>\n",
       "      <td>0.75904</td>\n",
       "      <td>0.6400</td>\n",
       "      <td>0.649169</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>52001</td>\n",
       "      <td>-0.151575</td>\n",
       "      <td>0.11316</td>\n",
       "      <td>0.75356</td>\n",
       "      <td>0.6404</td>\n",
       "      <td>0.640116</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>53001</td>\n",
       "      <td>-0.161753</td>\n",
       "      <td>0.11756</td>\n",
       "      <td>0.75756</td>\n",
       "      <td>0.6400</td>\n",
       "      <td>0.633637</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>54126</td>\n",
       "      <td>-0.159125</td>\n",
       "      <td>0.11892</td>\n",
       "      <td>0.75732</td>\n",
       "      <td>0.6384</td>\n",
       "      <td>0.639238</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>55126</td>\n",
       "      <td>-0.153709</td>\n",
       "      <td>0.12422</td>\n",
       "      <td>0.76372</td>\n",
       "      <td>0.6395</td>\n",
       "      <td>0.636300</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>56126</td>\n",
       "      <td>-0.159228</td>\n",
       "      <td>0.12544</td>\n",
       "      <td>0.76164</td>\n",
       "      <td>0.6362</td>\n",
       "      <td>0.637227</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>57251</td>\n",
       "      <td>-0.156503</td>\n",
       "      <td>0.13070</td>\n",
       "      <td>0.76950</td>\n",
       "      <td>0.6388</td>\n",
       "      <td>0.637130</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>58251</td>\n",
       "      <td>-0.156612</td>\n",
       "      <td>0.13614</td>\n",
       "      <td>0.77504</td>\n",
       "      <td>0.6389</td>\n",
       "      <td>0.647871</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>59251</td>\n",
       "      <td>-0.086866</td>\n",
       "      <td>0.13768</td>\n",
       "      <td>0.77618</td>\n",
       "      <td>0.6385</td>\n",
       "      <td>0.638676</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>60376</td>\n",
       "      <td>-0.120235</td>\n",
       "      <td>0.13278</td>\n",
       "      <td>0.77548</td>\n",
       "      <td>0.6427</td>\n",
       "      <td>0.646021</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>61376</td>\n",
       "      <td>-0.147571</td>\n",
       "      <td>0.13184</td>\n",
       "      <td>0.76754</td>\n",
       "      <td>0.6357</td>\n",
       "      <td>0.638378</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>62376</td>\n",
       "      <td>-0.146472</td>\n",
       "      <td>0.14042</td>\n",
       "      <td>0.77592</td>\n",
       "      <td>0.6355</td>\n",
       "      <td>0.632139</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   GlobStep  threshold    delta  phi_train  phi_holdout  estimate overfit\n",
       "0      1001   0.023347  0.00004    0.38264       0.3826  0.382640   False\n",
       "1      2001  -0.021424  0.00400    0.43760       0.4336  0.433547    True\n",
       "2      3001  -0.011971  0.00110    0.46220       0.4611  0.464234    True\n",
       "3      4126  -0.026733  0.00036    0.48314       0.4835  0.481943    True\n",
       "4      5126  -0.008287  0.00862    0.50972       0.5011  0.488755    True\n",
       "5      6126  -0.017283  0.01208    0.51908       0.5070  0.509735    True\n",
       "6      7251  -0.100606  0.00832    0.53922       0.5309  0.528483    True\n",
       "7      8251  -0.034976  0.01736    0.55686       0.5395  0.550288    True\n",
       "8      9251  -0.106600  0.01894    0.55994       0.5410  0.541197    True\n",
       "9     10376   0.008021  0.02036    0.56206       0.5417  0.537625    True\n",
       "10    11376   0.015296  0.01414    0.57724       0.5631  0.577240   False\n",
       "11    12376  -0.033169  0.02284    0.58604       0.5632  0.558417    True\n",
       "12    13501  -0.042710  0.02544    0.60204       0.5766  0.580373    True\n",
       "13    14501  -0.054156  0.02876    0.61136       0.5826  0.580223    True\n",
       "14    15501  -0.072477  0.02776    0.61116       0.5834  0.594310    True\n",
       "15    16626   0.008199  0.03006    0.60256       0.5725  0.572032    True\n",
       "16    17626   0.000888  0.03610    0.62570       0.5896  0.591406    True\n",
       "17    18626   0.000811  0.03606    0.62926       0.5932  0.588872    True\n",
       "18    19751  -0.032127  0.04130    0.63730       0.5960  0.603133    True\n",
       "19    20751  -0.069270  0.03540    0.62530       0.5899  0.583996    True\n",
       "20    21751  -0.084952  0.04752    0.65192       0.6044  0.621472    True\n",
       "21    22876  -0.070324  0.04204    0.64694       0.6049  0.612654    True\n",
       "22    23876  -0.064011  0.05004    0.66074       0.6107  0.608580    True\n",
       "23    24876  -0.066550  0.05082    0.65352       0.6027  0.603315    True\n",
       "24    26001  -0.082448  0.05770    0.67090       0.6132  0.616852    True\n",
       "25    27001  -0.111417  0.05942    0.67452       0.6151  0.616552    True\n",
       "26    28001  -0.086038  0.06304    0.68314       0.6201  0.624494    True\n",
       "27    29126  -0.082388  0.06670    0.68260       0.6159  0.612540    True\n",
       "28    30126  -0.082147  0.06094    0.68364       0.6227  0.621344    True\n",
       "29    31126  -0.100681  0.06270    0.67670       0.6140  0.610193    True\n",
       "30    32251  -0.041823  0.07106    0.69126       0.6202  0.620147    True\n",
       "31    33251  -0.060448  0.06856    0.69256       0.6240  0.619226    True\n",
       "32    34251  -0.165596  0.07464    0.70334       0.6287  0.615211    True\n",
       "33    35376  -0.118861  0.07672    0.70432       0.6276  0.636081    True\n",
       "34    36376  -0.095016  0.07700    0.70170       0.6247  0.625781    True\n",
       "35    37376  -0.100465  0.08012    0.71242       0.6323  0.653423    True\n",
       "36    38501  -0.119056  0.08180    0.71390       0.6321  0.636874    True\n",
       "37    39501  -0.112550  0.08682    0.71922       0.6324  0.627593    True\n",
       "38    40501  -0.190731  0.08598    0.71608       0.6301  0.627631    True\n",
       "39    41626  -0.084703  0.09154    0.73394       0.6424  0.644270    True\n",
       "40    42626  -0.145958  0.09758    0.72828       0.6307  0.631599    True\n",
       "41    43626  -0.153081  0.09062    0.71432       0.6237  0.619774    True\n",
       "42    44751  -0.167272  0.09378    0.72518       0.6314  0.632698    True\n",
       "43    45751  -0.093294  0.10268    0.73338       0.6307  0.630583    True\n",
       "44    46751  -0.155555  0.10058    0.72918       0.6286  0.629465    True\n",
       "45    47876  -0.175936  0.10834    0.74894       0.6406  0.640239    True\n",
       "46    48876  -0.189163  0.10980    0.74340       0.6336  0.639568    True\n",
       "47    49876  -0.197798  0.10550    0.73890       0.6334  0.635885    True\n",
       "48    51001  -0.142781  0.11904    0.75904       0.6400  0.649169    True\n",
       "49    52001  -0.151575  0.11316    0.75356       0.6404  0.640116    True\n",
       "50    53001  -0.161753  0.11756    0.75756       0.6400  0.633637    True\n",
       "51    54126  -0.159125  0.11892    0.75732       0.6384  0.639238    True\n",
       "52    55126  -0.153709  0.12422    0.76372       0.6395  0.636300    True\n",
       "53    56126  -0.159228  0.12544    0.76164       0.6362  0.637227    True\n",
       "54    57251  -0.156503  0.13070    0.76950       0.6388  0.637130    True\n",
       "55    58251  -0.156612  0.13614    0.77504       0.6389  0.647871    True\n",
       "56    59251  -0.086866  0.13768    0.77618       0.6385  0.638676    True\n",
       "57    60376  -0.120235  0.13278    0.77548       0.6427  0.646021    True\n",
       "58    61376  -0.147571  0.13184    0.76754       0.6357  0.638378    True\n",
       "59    62376  -0.146472  0.14042    0.77592       0.6355  0.632139    True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['overfit'] = df['delta'] > df['threshold']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GlobStep</th>\n",
       "      <th>threshold</th>\n",
       "      <th>delta</th>\n",
       "      <th>phi_train</th>\n",
       "      <th>phi_holdout</th>\n",
       "      <th>overfit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.006043</td>\n",
       "      <td>0.00004</td>\n",
       "      <td>0.37394</td>\n",
       "      <td>0.3739</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2001.0</td>\n",
       "      <td>0.012523</td>\n",
       "      <td>0.00182</td>\n",
       "      <td>0.43462</td>\n",
       "      <td>0.4328</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3001.0</td>\n",
       "      <td>0.065114</td>\n",
       "      <td>0.00594</td>\n",
       "      <td>0.45314</td>\n",
       "      <td>0.4472</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4126.0</td>\n",
       "      <td>0.007891</td>\n",
       "      <td>0.00720</td>\n",
       "      <td>0.49090</td>\n",
       "      <td>0.4837</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5126.0</td>\n",
       "      <td>0.059908</td>\n",
       "      <td>0.00678</td>\n",
       "      <td>0.51068</td>\n",
       "      <td>0.5039</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6126.0</td>\n",
       "      <td>0.046002</td>\n",
       "      <td>0.00408</td>\n",
       "      <td>0.52908</td>\n",
       "      <td>0.5250</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7251.0</td>\n",
       "      <td>0.014633</td>\n",
       "      <td>0.00792</td>\n",
       "      <td>0.54372</td>\n",
       "      <td>0.5358</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8251.0</td>\n",
       "      <td>-0.014221</td>\n",
       "      <td>0.01090</td>\n",
       "      <td>0.54690</td>\n",
       "      <td>0.5360</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9251.0</td>\n",
       "      <td>-0.005837</td>\n",
       "      <td>0.01360</td>\n",
       "      <td>0.55890</td>\n",
       "      <td>0.5453</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10376.0</td>\n",
       "      <td>-0.002225</td>\n",
       "      <td>0.01480</td>\n",
       "      <td>0.57200</td>\n",
       "      <td>0.5572</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>11376.0</td>\n",
       "      <td>0.028258</td>\n",
       "      <td>0.01480</td>\n",
       "      <td>0.58570</td>\n",
       "      <td>0.5709</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>12376.0</td>\n",
       "      <td>0.020945</td>\n",
       "      <td>0.01786</td>\n",
       "      <td>0.58586</td>\n",
       "      <td>0.5680</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>13501.0</td>\n",
       "      <td>0.036306</td>\n",
       "      <td>0.01806</td>\n",
       "      <td>0.60016</td>\n",
       "      <td>0.5821</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14501.0</td>\n",
       "      <td>-0.022103</td>\n",
       "      <td>0.01614</td>\n",
       "      <td>0.59794</td>\n",
       "      <td>0.5818</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>15501.0</td>\n",
       "      <td>0.002492</td>\n",
       "      <td>0.02548</td>\n",
       "      <td>0.59298</td>\n",
       "      <td>0.5675</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>16626.0</td>\n",
       "      <td>0.003808</td>\n",
       "      <td>0.02766</td>\n",
       "      <td>0.61916</td>\n",
       "      <td>0.5915</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>17626.0</td>\n",
       "      <td>-0.025019</td>\n",
       "      <td>0.02798</td>\n",
       "      <td>0.62098</td>\n",
       "      <td>0.5930</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18626.0</td>\n",
       "      <td>0.018460</td>\n",
       "      <td>0.02812</td>\n",
       "      <td>0.61132</td>\n",
       "      <td>0.5832</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>19751.0</td>\n",
       "      <td>0.011637</td>\n",
       "      <td>0.03096</td>\n",
       "      <td>0.63256</td>\n",
       "      <td>0.6016</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>20751.0</td>\n",
       "      <td>-0.013460</td>\n",
       "      <td>0.03558</td>\n",
       "      <td>0.64168</td>\n",
       "      <td>0.6061</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>21751.0</td>\n",
       "      <td>-0.001525</td>\n",
       "      <td>0.03474</td>\n",
       "      <td>0.64434</td>\n",
       "      <td>0.6096</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>22876.0</td>\n",
       "      <td>-0.022761</td>\n",
       "      <td>0.03970</td>\n",
       "      <td>0.65190</td>\n",
       "      <td>0.6122</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>23876.0</td>\n",
       "      <td>-0.138846</td>\n",
       "      <td>0.04024</td>\n",
       "      <td>0.65434</td>\n",
       "      <td>0.6141</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>24876.0</td>\n",
       "      <td>-0.018032</td>\n",
       "      <td>0.04364</td>\n",
       "      <td>0.65444</td>\n",
       "      <td>0.6108</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>26001.0</td>\n",
       "      <td>0.069395</td>\n",
       "      <td>0.04610</td>\n",
       "      <td>0.65750</td>\n",
       "      <td>0.6114</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>27001.0</td>\n",
       "      <td>-0.001698</td>\n",
       "      <td>0.04740</td>\n",
       "      <td>0.67080</td>\n",
       "      <td>0.6234</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>28001.0</td>\n",
       "      <td>-0.011728</td>\n",
       "      <td>0.05152</td>\n",
       "      <td>0.67752</td>\n",
       "      <td>0.6260</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>29126.0</td>\n",
       "      <td>-0.021320</td>\n",
       "      <td>0.05468</td>\n",
       "      <td>0.68128</td>\n",
       "      <td>0.6266</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>30126.0</td>\n",
       "      <td>-0.015865</td>\n",
       "      <td>0.04718</td>\n",
       "      <td>0.68418</td>\n",
       "      <td>0.6370</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>31126.0</td>\n",
       "      <td>-0.030824</td>\n",
       "      <td>0.06286</td>\n",
       "      <td>0.68716</td>\n",
       "      <td>0.6243</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>32251.0</td>\n",
       "      <td>0.015098</td>\n",
       "      <td>0.05810</td>\n",
       "      <td>0.68200</td>\n",
       "      <td>0.6239</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>33251.0</td>\n",
       "      <td>0.002964</td>\n",
       "      <td>0.06114</td>\n",
       "      <td>0.69524</td>\n",
       "      <td>0.6341</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>34251.0</td>\n",
       "      <td>0.046582</td>\n",
       "      <td>0.06106</td>\n",
       "      <td>0.69336</td>\n",
       "      <td>0.6323</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>35376.0</td>\n",
       "      <td>0.017713</td>\n",
       "      <td>0.06640</td>\n",
       "      <td>0.71030</td>\n",
       "      <td>0.6439</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>36376.0</td>\n",
       "      <td>0.052740</td>\n",
       "      <td>0.06578</td>\n",
       "      <td>0.70038</td>\n",
       "      <td>0.6346</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>37376.0</td>\n",
       "      <td>0.059470</td>\n",
       "      <td>0.06576</td>\n",
       "      <td>0.70926</td>\n",
       "      <td>0.6435</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>38501.0</td>\n",
       "      <td>0.040238</td>\n",
       "      <td>0.07502</td>\n",
       "      <td>0.71682</td>\n",
       "      <td>0.6418</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>39501.0</td>\n",
       "      <td>0.062772</td>\n",
       "      <td>0.07522</td>\n",
       "      <td>0.71972</td>\n",
       "      <td>0.6445</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>40501.0</td>\n",
       "      <td>0.046936</td>\n",
       "      <td>0.07308</td>\n",
       "      <td>0.70238</td>\n",
       "      <td>0.6293</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>41626.0</td>\n",
       "      <td>0.033772</td>\n",
       "      <td>0.07124</td>\n",
       "      <td>0.72364</td>\n",
       "      <td>0.6524</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>42626.0</td>\n",
       "      <td>0.061022</td>\n",
       "      <td>0.08074</td>\n",
       "      <td>0.72694</td>\n",
       "      <td>0.6462</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>43626.0</td>\n",
       "      <td>0.050268</td>\n",
       "      <td>0.07394</td>\n",
       "      <td>0.70774</td>\n",
       "      <td>0.6338</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>44751.0</td>\n",
       "      <td>0.070491</td>\n",
       "      <td>0.08426</td>\n",
       "      <td>0.73216</td>\n",
       "      <td>0.6479</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>45751.0</td>\n",
       "      <td>-0.001234</td>\n",
       "      <td>0.08292</td>\n",
       "      <td>0.73022</td>\n",
       "      <td>0.6473</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>46751.0</td>\n",
       "      <td>0.030922</td>\n",
       "      <td>0.08608</td>\n",
       "      <td>0.73718</td>\n",
       "      <td>0.6511</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>47876.0</td>\n",
       "      <td>0.047950</td>\n",
       "      <td>0.09414</td>\n",
       "      <td>0.74134</td>\n",
       "      <td>0.6472</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>48876.0</td>\n",
       "      <td>0.038807</td>\n",
       "      <td>0.09098</td>\n",
       "      <td>0.73478</td>\n",
       "      <td>0.6438</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>49876.0</td>\n",
       "      <td>0.055255</td>\n",
       "      <td>0.09904</td>\n",
       "      <td>0.74024</td>\n",
       "      <td>0.6412</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>51001.0</td>\n",
       "      <td>0.075856</td>\n",
       "      <td>0.09398</td>\n",
       "      <td>0.73748</td>\n",
       "      <td>0.6435</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>52001.0</td>\n",
       "      <td>0.039399</td>\n",
       "      <td>0.10314</td>\n",
       "      <td>0.74654</td>\n",
       "      <td>0.6434</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>53001.0</td>\n",
       "      <td>0.072417</td>\n",
       "      <td>0.10254</td>\n",
       "      <td>0.74724</td>\n",
       "      <td>0.6447</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>54126.0</td>\n",
       "      <td>0.064481</td>\n",
       "      <td>0.10562</td>\n",
       "      <td>0.75592</td>\n",
       "      <td>0.6503</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>55126.0</td>\n",
       "      <td>0.017745</td>\n",
       "      <td>0.10966</td>\n",
       "      <td>0.75856</td>\n",
       "      <td>0.6489</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>56126.0</td>\n",
       "      <td>-0.000264</td>\n",
       "      <td>0.10284</td>\n",
       "      <td>0.74604</td>\n",
       "      <td>0.6432</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>57251.0</td>\n",
       "      <td>-0.007478</td>\n",
       "      <td>0.10446</td>\n",
       "      <td>0.74486</td>\n",
       "      <td>0.6404</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>58251.0</td>\n",
       "      <td>0.103552</td>\n",
       "      <td>0.11856</td>\n",
       "      <td>0.76266</td>\n",
       "      <td>0.6441</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>59251.0</td>\n",
       "      <td>0.066593</td>\n",
       "      <td>0.11160</td>\n",
       "      <td>0.76530</td>\n",
       "      <td>0.6537</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>60376.0</td>\n",
       "      <td>0.047135</td>\n",
       "      <td>0.11946</td>\n",
       "      <td>0.77046</td>\n",
       "      <td>0.6510</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>61376.0</td>\n",
       "      <td>0.021125</td>\n",
       "      <td>0.12048</td>\n",
       "      <td>0.76668</td>\n",
       "      <td>0.6462</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>62376.0</td>\n",
       "      <td>0.021226</td>\n",
       "      <td>0.11632</td>\n",
       "      <td>0.76532</td>\n",
       "      <td>0.6490</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    GlobStep  threshold    delta  phi_train  phi_holdout  overfit\n",
       "0     1001.0   0.006043  0.00004    0.37394       0.3739    False\n",
       "1     2001.0   0.012523  0.00182    0.43462       0.4328    False\n",
       "2     3001.0   0.065114  0.00594    0.45314       0.4472    False\n",
       "3     4126.0   0.007891  0.00720    0.49090       0.4837    False\n",
       "4     5126.0   0.059908  0.00678    0.51068       0.5039    False\n",
       "5     6126.0   0.046002  0.00408    0.52908       0.5250    False\n",
       "6     7251.0   0.014633  0.00792    0.54372       0.5358    False\n",
       "7     8251.0  -0.014221  0.01090    0.54690       0.5360     True\n",
       "8     9251.0  -0.005837  0.01360    0.55890       0.5453     True\n",
       "9    10376.0  -0.002225  0.01480    0.57200       0.5572     True\n",
       "10   11376.0   0.028258  0.01480    0.58570       0.5709    False\n",
       "11   12376.0   0.020945  0.01786    0.58586       0.5680    False\n",
       "12   13501.0   0.036306  0.01806    0.60016       0.5821    False\n",
       "13   14501.0  -0.022103  0.01614    0.59794       0.5818     True\n",
       "14   15501.0   0.002492  0.02548    0.59298       0.5675     True\n",
       "15   16626.0   0.003808  0.02766    0.61916       0.5915     True\n",
       "16   17626.0  -0.025019  0.02798    0.62098       0.5930     True\n",
       "17   18626.0   0.018460  0.02812    0.61132       0.5832     True\n",
       "18   19751.0   0.011637  0.03096    0.63256       0.6016     True\n",
       "19   20751.0  -0.013460  0.03558    0.64168       0.6061     True\n",
       "20   21751.0  -0.001525  0.03474    0.64434       0.6096     True\n",
       "21   22876.0  -0.022761  0.03970    0.65190       0.6122     True\n",
       "22   23876.0  -0.138846  0.04024    0.65434       0.6141     True\n",
       "23   24876.0  -0.018032  0.04364    0.65444       0.6108     True\n",
       "24   26001.0   0.069395  0.04610    0.65750       0.6114    False\n",
       "25   27001.0  -0.001698  0.04740    0.67080       0.6234     True\n",
       "26   28001.0  -0.011728  0.05152    0.67752       0.6260     True\n",
       "27   29126.0  -0.021320  0.05468    0.68128       0.6266     True\n",
       "28   30126.0  -0.015865  0.04718    0.68418       0.6370     True\n",
       "29   31126.0  -0.030824  0.06286    0.68716       0.6243     True\n",
       "30   32251.0   0.015098  0.05810    0.68200       0.6239     True\n",
       "31   33251.0   0.002964  0.06114    0.69524       0.6341     True\n",
       "32   34251.0   0.046582  0.06106    0.69336       0.6323     True\n",
       "33   35376.0   0.017713  0.06640    0.71030       0.6439     True\n",
       "34   36376.0   0.052740  0.06578    0.70038       0.6346     True\n",
       "35   37376.0   0.059470  0.06576    0.70926       0.6435     True\n",
       "36   38501.0   0.040238  0.07502    0.71682       0.6418     True\n",
       "37   39501.0   0.062772  0.07522    0.71972       0.6445     True\n",
       "38   40501.0   0.046936  0.07308    0.70238       0.6293     True\n",
       "39   41626.0   0.033772  0.07124    0.72364       0.6524     True\n",
       "40   42626.0   0.061022  0.08074    0.72694       0.6462     True\n",
       "41   43626.0   0.050268  0.07394    0.70774       0.6338     True\n",
       "42   44751.0   0.070491  0.08426    0.73216       0.6479     True\n",
       "43   45751.0  -0.001234  0.08292    0.73022       0.6473     True\n",
       "44   46751.0   0.030922  0.08608    0.73718       0.6511     True\n",
       "45   47876.0   0.047950  0.09414    0.74134       0.6472     True\n",
       "46   48876.0   0.038807  0.09098    0.73478       0.6438     True\n",
       "47   49876.0   0.055255  0.09904    0.74024       0.6412     True\n",
       "48   51001.0   0.075856  0.09398    0.73748       0.6435     True\n",
       "49   52001.0   0.039399  0.10314    0.74654       0.6434     True\n",
       "50   53001.0   0.072417  0.10254    0.74724       0.6447     True\n",
       "51   54126.0   0.064481  0.10562    0.75592       0.6503     True\n",
       "52   55126.0   0.017745  0.10966    0.75856       0.6489     True\n",
       "53   56126.0  -0.000264  0.10284    0.74604       0.6432     True\n",
       "54   57251.0  -0.007478  0.10446    0.74486       0.6404     True\n",
       "55   58251.0   0.103552  0.11856    0.76266       0.6441     True\n",
       "56   59251.0   0.066593  0.11160    0.76530       0.6537     True\n",
       "57   60376.0   0.047135  0.11946    0.77046       0.6510     True\n",
       "58   61376.0   0.021125  0.12048    0.76668       0.6462     True\n",
       "59   62376.0   0.021226  0.11632    0.76532       0.6490     True"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f89b2beaf98>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x432 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(data=df, x=\"GlobStep\", y=\"delta\", hue='overfit')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
